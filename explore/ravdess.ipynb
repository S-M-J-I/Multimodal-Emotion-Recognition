{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "modules = [\n",
    "    os.path.abspath(os.getcwd() + '\\\\..'),\n",
    "    os.path.abspath(os.getcwd() + '\\\\..\\src'),\n",
    "    os.path.abspath(os.getcwd() + '\\\\../src/audio_network'),\n",
    "    os.path.abspath(os.getcwd() + '\\\\../src/video_network'),\n",
    "    os.path.abspath(os.getcwd() + '\\\\../src/multimodal_network'),\n",
    "    os.path.abspath(os.getcwd() + '\\\\../src/utils'),\n",
    "    os.path.abspath(os.getcwd() + '\\\\../src/utils/configs'),\n",
    "    os.path.abspath(os.getcwd() + '\\\\../src/utils/datasets'),\n",
    "    os.path.abspath(os.getcwd() + '\\\\../src/utils/helpers'),\n",
    "    os.path.abspath(os.getcwd() + '\\\\../src/utils/transforms'),\n",
    "]\n",
    "\n",
    "\n",
    "for module in modules:\n",
    "    if module not in sys.path:\n",
    "        print(module)\n",
    "        sys.path.append(module)\n",
    "\n",
    "\n",
    "from src.utils.configs.hyperparams import hyperparams\n",
    "from src.utils.transforms.video_transforms import *\n",
    "from src.utils.transforms.audio_transforms import *\n",
    "from src.utils.configs.ravdess import *\n",
    "from src.utils.helpers.functions import *\n",
    "from src.utils.datasets.dataset import *\n",
    "from src.multimodal_network.multimodal import MainMultimodal\n",
    "\n",
    "from src.utils.helpers.loops import *\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load device configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the data and turn into dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_augment_df = RAVDESSConfigs().make_dataframe(\"<path_to_ravdess_dir>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_1_df = non_augment_df.copy()\n",
    "augment_1_df[\"augment\"] = 1\n",
    "\n",
    "augment_2_df = non_augment_df.copy()\n",
    "augment_2_df[\"augment\"] = 2\n",
    "\n",
    "non_augment_df[\"augment\"] = 0\n",
    "\n",
    "# check an example to see if the strings/naming conventions match\n",
    "non_augment_df[\"audio_path\"][0], non_augment_df[\"video_path\"][0], augment_1_df[\"audio_path\"][0], augment_1_df[\"video_path\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_augment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([non_augment_df, augment_1_df, augment_2_df])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(non_augment_df), len(augment_1_df), len(augment_2_df), len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train:val:test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 60% train, 20% val, 20% test set\n",
    "train_df, test_df = train_test_split(df, test_size=0.40, shuffle=True, random_state=42)\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your examples\n",
    "idx = 90 # Change index to see different examples\n",
    "show_example(train_df[\"video_path\"].iloc[idx], train_df[\"audio_path\"].iloc[idx], actual=train_df[\"label\"].iloc[idx], idx2class=RAVDESSConfigs().idx2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df, test_df = train_test_split(test_df, test_size=0.50, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View their length\n",
    "len(train_df), len(cv_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df, non_augment_df, augment_1_df, augment_2_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Form the dataloaders (preprocessing phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainds = Dataset(train_df, video_frame_transform, video_strategy='optimal', device=device)\n",
    "cvds = Dataset(cv_df, video_frame_transform, video_strategy='optimal', device=device)\n",
    "testds = Dataset(test_df, video_frame_transform, video_strategy='optimal', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainds, batch_size=hyperparams[\"batch\"], shuffle=True)\n",
    "cvloader = DataLoader(cvds, batch_size=hyperparams[\"batch\"], shuffle=False)\n",
    "testloader = DataLoader(testds, batch_size=hyperparams[\"batch\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainds\n",
    "del cvds\n",
    "del testds\n",
    "del train_df\n",
    "del cv_df\n",
    "del test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MainMultimodal(num_classes=len(RAVDESSConfigs().class2idx), fine_tune_limit=3).to(device=device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(params=model.parameters(), lr=hyperparams[\"lr\"], betas=hyperparams[\"adam_betas\"], weight_decay=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = []\n",
    "train_loss_history = []\n",
    "eval_loss_history = []\n",
    "\n",
    "train_accuracy_history = []\n",
    "eval_accuracy_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {}\n",
    "best_train_loss, best_eval_loss = 10000, 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "save_memory = True\n",
    "\n",
    "if save_memory:\n",
    "    print(\"\\tSave memory mode is on. Set `save_memory=False` to see video-audio examples\")\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(hyperparams[\"epochs\"]):\n",
    "    print(f\"========================== Starting Epoch: # {epoch} ==========================\")\n",
    "\n",
    "    inference_start = time.time()\n",
    "\n",
    "    train_loss, train_acc = train_step(model, trainloader, optim, loss_fn, RAVDESSConfigs().idx2class, multiclass_f1_score, save_memory=save_memory, device=device)\n",
    "    eval_loss, eval_acc = eval_step(model, cvloader, loss_fn, RAVDESSConfigs().idx2class, multiclass_f1_score, save_memory=save_memory, device=device)\n",
    "\n",
    "    inference_total = time.time() - inference_start\n",
    "\n",
    "\n",
    "    print(f\"Epoch: #{epoch} | Total Train Loss: {train_loss} | Total Eval. Loss: {eval_loss} | Train Acc: {train_acc * 100}% | Eval Acc: {eval_acc * 100}% in {inference_total} seconds\")\n",
    "\n",
    "\n",
    "    epochs.append(epoch+1)\n",
    "    train_loss_history.append(train_loss)\n",
    "    eval_loss_history.append(eval_loss)\n",
    "    train_accuracy_history.append(train_acc.detach().cpu()*100)\n",
    "    eval_accuracy_history.append(eval_acc.detach().cpu()*100)\n",
    "\n",
    "    if train_loss < best_train_loss and eval_loss < best_eval_loss:\n",
    "        best_train_loss, best_eval_loss = train_loss, eval_loss\n",
    "        torch.save(model.state_dict(), \"./best-multimodal_ravdess.pt\")\n",
    "        best_w = model.state_dict()\n",
    "\n",
    "    del train_loss, eval_loss, train_acc, eval_acc\n",
    "\n",
    "    if device == \"cuda\" or device.find(\"cuda\") >= 0:\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "total = end - start\n",
    "convert = str(datetime.timedelta(seconds=total))\n",
    "print(f\"Total Training Time: {total}s => {convert}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./multimodal-final_ravdess.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch = hyperparams[\"epochs\"]\n",
    "epoch = len(epochs)\n",
    "\n",
    "plt.plot(epochs, train_loss_history, color='dodgerblue', label='Train Loss')\n",
    "plt.plot(epochs, eval_loss_history, color='orange', label='Eval. Loss')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.title(f\"Train and Eval. Loss along {epoch} epochs (RAVDESS)\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"./Loss curves.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, train_accuracy_history, color='dodgerblue', label='Train Accuracy')\n",
    "plt.plot(epochs, eval_accuracy_history, color='orange', label='Eval. Accuracy')\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"F1 Score Value\")\n",
    "plt.title(f\"Train and Eval. Accuracy along {epoch} epochs (RAVDESS)\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.savefig(\"./F1-Score curves.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best weights model\n",
    "model.load_state_dict(torch.load('./best-multimodal_ravdess.pt'))\n",
    "\n",
    "\n",
    "test_loss, test_acc, y_true, y_preds = eval_step(model, testloader, loss_fn, multiclass_f1_score, save_memory=False, confusion_matrix=True)\n",
    "test_acc = test_acc.detach().cpu()\n",
    "\n",
    "print(f\"Test loss: {test_loss}\\tTest Accuracy: {test_acc*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [v for k,v in RAVDESSConfigs().idx2class.items()]\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true, y_preds)\n",
    "\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes], columns = [i for i in classes])\n",
    "\n",
    "plt.figure(figsize = (12,7))\n",
    "\n",
    "s = sn.heatmap(df_cm, annot=True, cmap='Blues', fmt=\".2f\")\n",
    "\n",
    "plt.xlabel('Predicted Label', fontsize=14, labelpad=20, fontweight='bold')\n",
    "\n",
    "plt.ylabel('True Label', fontsize=14, labelpad=20, fontweight='bold')\n",
    "\n",
    "plt.savefig('./confusion_matrix_savee.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_preds, target_names=[v for k,v in RAVDESSConfigs().idx2class.items()], output_dict=True)\n",
    "\n",
    "df = pd.DataFrame(report).transpose()\n",
    "\n",
    "df = df.round(decimals=4)\n",
    "\n",
    "df.to_csv('./classification_report.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save stats\n",
    "# with open(\"./recorded.txt\", \"w\") as f:\n",
    "#     f.write(\"R2plus1D & CNN-SE attempt on RAVDESS\\n\")\n",
    "#     for i, line in enumerate(epochs):\n",
    "#         f.write(f\"Epoch: {line}: | Train Loss: {train_loss_history[i]} | Train Accuracy: {train_accuracy_history[i]} | Eval Loss: {eval_loss_history[i]} | Eval Accuracy: {eval_accuracy_history[i]}\")\n",
    "#         f.write(\"\\n\")\n",
    "\n",
    "#     f.write(\"\\n==================================================\\n\")\n",
    "#     f.write(f\"On best weights => Test loss: {test_loss}\\tTest Accuracy: {test_acc*100}\")\n",
    "#     f.write(\"\\n==================================================\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
