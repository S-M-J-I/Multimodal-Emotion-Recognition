# Hyperparameters. Tweak as you wish
hyperparams = {
    "lr": 0.0001,  # Learning Rate
    "epochs": 30,  # Number of Epochs
    "adam_betas": (0.98, 0.999),  # B1 and B2 (weight decays) of ADAM
    "batch": 16,  # Mini-batch size
    "sdg_momentum": 0.99,  # Stochastic Gradient Descent momentum
    "sdg_weight_decay": 0.45,  # Stochastic Gradient Descent weight decay,
}
