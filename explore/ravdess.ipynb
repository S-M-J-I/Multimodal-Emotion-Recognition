{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.utils.configs.hyperparams import hyperparams\n",
    "from src.utils.transforms.video_transforms import *\n",
    "from src.utils.transforms.audio_transforms import *\n",
    "from src.utils.configs.ravdess import *\n",
    "from src.utils.helpers.functions import *\n",
    "from src.utils.datasets.ravdess import *\n",
    "from src.multimodal_network.multimodal import MainMultimodal\n",
    "\n",
    "from src.utils.helpers.loops import *\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "\n",
    "from torcheval.metrics.functional import multiclass_f1_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_augment_df = RAVDESSConfigs().make_dataframe(\"<path_to_ravdess_dir>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_1_df = non_augment_df.copy()\n",
    "augment_1_df[\"augment\"] = 1\n",
    "\n",
    "augment_2_df = non_augment_df.copy()\n",
    "augment_2_df[\"augment\"] = 2\n",
    "\n",
    "non_augment_df[\"augment\"] = 0\n",
    "\n",
    "# check an example to see if the strings/naming conventions match\n",
    "non_augment_df[\"audio_path\"][0], non_augment_df[\"video_path\"][0], augment_1_df[\"audio_path\"][0], augment_1_df[\"video_path\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 50\n",
    "\n",
    "\n",
    "# # RAW AUDIO\n",
    "# d = feature_extractor(non_augment_df[\"audio_path\"][idx], augment=0, test=True)\n",
    "# data = d[\"raw\"]\n",
    "# sr = d[\"sr\"]\n",
    "# print(\"Audio transformed with augmentation scheme 0 (no augementation; raw audio):\")\n",
    "# ipd.display(ipd.Audio(data=data, rate=sr))\n",
    "# print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # AUGMENTATION 1 - harmonic\n",
    "# d = feature_extractor(augment_1_df[\"audio_path\"][idx], augment=1, test=True)\n",
    "# data = d[\"raw\"]\n",
    "# sr = d[\"sr\"]\n",
    "# print(\"Audio transformed with augmentation scheme 1:\")\n",
    "# ipd.display(ipd.Audio(data=data, rate=sr))\n",
    "# print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # AUGMENTATION 2 - pitch shift\n",
    "# d = feature_extractor(augment_2_df[\"audio_path\"][idx], augment=2, test=True)\n",
    "# data = d[\"raw\"]\n",
    "# sr = d[\"sr\"]\n",
    "# print(\"Audio transformed with augmentation scheme 2:\")\n",
    "# ipd.display(ipd.Audio(data=data, rate=sr))\n",
    "# print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_augment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([non_augment_df, augment_1_df, augment_2_df])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(non_augment_df), len(augment_1_df), len(augment_2_df), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 60% train, 20% val, 20% test set\n",
    "train_df, test_df = train_test_split(df, test_size=0.40, shuffle=True, random_state=42)\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your examples\n",
    "idx = 90 # Change index to see different examples\n",
    "show_example(train_df[\"video_path\"].iloc[idx], train_df[\"audio_path\"].iloc[idx], actual=train_df[\"label\"].iloc[idx], idx2class=RAVDESSConfigs.idx2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_df, test_df = train_test_split(test_df, test_size=0.50, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View their length\n",
    "len(train_df), len(cv_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df, non_augment_df, augment_1_df, augment_2_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainds = RAVDESSDataset(train_df, video_frame_transform, video_strategy='optimal')\n",
    "cvds = RAVDESSDataset(cv_df, video_frame_transform, video_strategy='optimal')\n",
    "testds = RAVDESSDataset(test_df, video_frame_transform, video_strategy='optimal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainds, batch_size=hyperparams[\"batch\"], shuffle=True)\n",
    "cvloader = DataLoader(cvds, batch_size=hyperparams[\"batch\"], shuffle=False)\n",
    "testloader = DataLoader(testds, batch_size=hyperparams[\"batch\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainds\n",
    "del cvds\n",
    "del testds\n",
    "del train_df\n",
    "del cv_df\n",
    "del test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_a_loader(item, i):\n",
    "    video, audio, label, video_p, audio_p = item\n",
    "    show_example(video_p[i], audio_p[i], label[i].item(), label[i].item())\n",
    "    print(f\"Video shape: {video.shape} | Audio shape: {audio['mel'].shape}\")\n",
    "    print(f\"{video_p[i]}\")\n",
    "    for f in video[i]:\n",
    "        f = torch.permute(f, (1,2,0))\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.imshow(f.numpy())\n",
    "        plt.show()\n",
    "#     imgSpec(audio[i].squeeze())\n",
    "\n",
    "    del item, video, audio, label, video_p, audio_p\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item1 = next(iter(trainloader))\n",
    "# item2 = next(iter(trainloader))\n",
    "# item3 = next(iter(trainloader))\n",
    "# item4 = next(iter(trainloader))\n",
    "# item5 = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# item2 - 0; raw unfiltered\n",
    "# item1 - 0; color jittered\n",
    "# item3 - 0; prespective\n",
    "\n",
    "# view_a_loader(item2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MainMultimodal(num_classes=len(RAVDESSConfigs.class2idx), fine_tune_limit=3).to(device=device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(params=model.parameters(), lr=hyperparams[\"lr\"], betas=hyperparams[\"adam_betas\"], weight_decay=1e-2)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = []\n",
    "train_loss_history = []\n",
    "eval_loss_history = []\n",
    "\n",
    "train_accuracy_history = []\n",
    "eval_accuracy_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {}\n",
    "best_train_loss, best_eval_loss = 10000, 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "save_memory = True\n",
    "\n",
    "if save_memory:\n",
    "    print(\"\\tSave memory mode is on. Set `save_memory=False` to see video-audio examples\")\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(hyperparams[\"epochs\"]):\n",
    "    print(f\"========================== Starting Epoch: # {epoch} ==========================\")\n",
    "\n",
    "    inference_start = time.time()\n",
    "\n",
    "    train_loss, train_acc = train_step(model, trainloader, optim, loss_fn, multiclass_f1_score, save_memory=save_memory, idx2class=RAVDESSConfigs.idx2class)\n",
    "    eval_loss, eval_acc = eval_step(model, cvloader, loss_fn, multiclass_f1_score, save_memory=save_memory, idx2class=RAVDESSConfigs.idx2class)\n",
    "\n",
    "    inference_total = time.time() - inference_start\n",
    "\n",
    "\n",
    "    print(f\"Epoch: #{epoch} | Total Train Loss: {train_loss} | Total Eval. Loss: {eval_loss} | Train Acc: {train_acc * 100}% | Eval Acc: {eval_acc * 100}% in {inference_total} seconds\")\n",
    "\n",
    "\n",
    "    epochs.append(epoch+1)\n",
    "    train_loss_history.append(train_loss)\n",
    "    eval_loss_history.append(eval_loss)\n",
    "    train_accuracy_history.append(train_acc.detach().cpu()*100)\n",
    "    eval_accuracy_history.append(eval_acc.detach().cpu()*100)\n",
    "\n",
    "    if train_loss < best_train_loss and eval_loss < best_eval_loss:\n",
    "        best_train_loss, best_eval_loss = train_loss, eval_loss\n",
    "        torch.save(model.state_dict(), \"./best-multimodal.pt\")\n",
    "        best_w = model.state_dict()\n",
    "\n",
    "    del train_loss, eval_loss, train_acc, eval_acc\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "end = time.time()\n",
    "total = end - start\n",
    "convert = str(datetime.timedelta(seconds=total))\n",
    "print(f\"Total Training Time: {total}s => {convert}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./multimodal-final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# epoch = hyperparams[\"epochs\"]\n",
    "epoch = len(epochs)\n",
    "\n",
    "plt.plot(epochs, train_loss_history, color='dodgerblue', label='Train Loss')\n",
    "plt.plot(epochs, eval_loss_history, color='orange', label='Eval. Loss')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.title(f\"Train and Eval. Loss along {epoch} epochs (RAVDESS)\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"./Loss curves.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, train_accuracy_history, color='dodgerblue', label='Train Accuracy')\n",
    "plt.plot(epochs, eval_accuracy_history, color='orange', label='Eval. Accuracy')\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"F1 Score Value\")\n",
    "plt.title(f\"Train and Eval. Accuracy along {epoch} epochs (RAVDESS)\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.savefig(\"./F1-Score curves.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best weights model\n",
    "model.load_state_dict(torch.load('./best-multimodal.pt'))\n",
    "\n",
    "\n",
    "test_loss, test_acc, y_true, y_preds = eval_step(model, testloader, loss_fn, multiclass_f1_score, save_memory=False, confusion_matrix=True)\n",
    "test_acc = test_acc.detach().cpu()\n",
    "\n",
    "print(f\"Test loss: {test_loss}\\tTest Accuracy: {test_acc*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [v for k,v in RAVDESSConfigs.idx2class.items()]\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true, y_preds)\n",
    "\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes], columns = [i for i in classes])\n",
    "\n",
    "plt.figure(figsize = (12,7))\n",
    "\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "\n",
    "plt.savefig('./confusion_matrix_savee.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save stats\n",
    "with open(\"./recorded.txt\", \"w\") as f:\n",
    "    f.write(\"R2plus1D & CNN-SE attempt\\n\")\n",
    "    for i, line in enumerate(epochs):\n",
    "        f.write(f\"Epoch: {line}: | Train Loss: {train_loss_history[i]} | Train Accuracy: {train_accuracy_history[i]} | Eval Loss: {eval_loss_history[i]} | Eval Accuracy: {eval_accuracy_history[i]}\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    f.write(\"\\n==================================================\\n\")\n",
    "    f.write(f\"On best weights => Test loss: {test_loss}\\tTest Accuracy: {test_acc*100}\")\n",
    "    f.write(\"\\n==================================================\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
