# Emotion Recognition using Multi-modal Deep Learning

Link: 


## Requirements

Clone this repository:
```sh
git clone https://github.com/S-M-J-I/Multimodal-Emotion-Recognition
```

If you have SSH configured:
```sh
git clone git@github.com:S-M-J-I/Multimodal-Emotion-Recognition.git
```

And run:
```sh
pip install -r requirements.txt
```


## Run the pipelines

To run the notebooks on SAVEE and RAVDESS, we recommend you download the dataset and unpack it in this directory. Then set the path for in their respective notebooks.\
**Note: while setting the file path, ensure the exta '/' is added to the end. Example: `/path_to_dir/`**

To run the model on the datasets, navigate to the individual notebooks made for them in the [explore](./explore/) directory.

Run the following command in the terminal to start the local server:
```sh
pipenv run jupyter notebook
```

## Weights
To obtain the weights of the model, kindly access the following [link](https://drive.google.com/drive/folders/141iQxVmjnL0zsWhjmakI6stK2CdoeRln?usp=sharing)

For any assistance or issues, kindly open an Issue in this repository.