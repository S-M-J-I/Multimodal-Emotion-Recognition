{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lR0lWYje5kX"
      },
      "source": [
        "# **Emotion Recognition using Multimodal Deep Learning Approaches**\n",
        "\n",
        "In this experiment we propose a novel Multimodal Architecture to predict 8 different human emotions. We use audio and video as inputs to our model. The dataset this notebook runs on is the SAVEE datatset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibhyWildbSQ4",
        "outputId": "a1db7786-237d-4301-afe5-4470e106498d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting av\n",
            "  Downloading av-10.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.0/31.0 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-10.0.0\n",
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.6-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.4/158.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchtnt>=0.0.5 (from torcheval)\n",
            "  Downloading torchtnt-0.1.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (1.22.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (2023.6.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (2.12.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (5.9.5)\n",
            "Collecting pyre-extensions (from torchtnt>=0.0.5->torcheval)\n",
            "  Downloading pyre_extensions-0.0.30-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (67.7.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtnt>=0.0.5->torcheval) (4.65.0)\n",
            "Collecting typing-inspect (from pyre-extensions->torchtnt>=0.0.5->torcheval)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.56.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (3.4.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (2.3.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->torchtnt>=0.0.5->torcheval) (0.40.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtnt>=0.0.5->torcheval) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtnt>=0.0.5->torcheval) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->torchtnt>=0.0.5->torcheval) (16.0.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtnt>=0.0.5->torcheval) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->torchtnt>=0.0.5->torcheval) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->torchtnt>=0.0.5->torcheval) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtnt>=0.0.5->torcheval) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect->pyre-extensions->torchtnt>=0.0.5->torcheval)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->torchtnt>=0.0.5->torcheval) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->torchtnt>=0.0.5->torcheval) (3.2.2)\n",
            "Installing collected packages: mypy-extensions, typing-inspect, pyre-extensions, torchtnt, torcheval\n",
            "Successfully installed mypy-extensions-1.0.0 pyre-extensions-0.0.30 torcheval-0.0.6 torchtnt-0.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install av\n",
        "\n",
        "try:\n",
        "    from torchsummary import summary\n",
        "except:\n",
        "    !pip install torchsummary\n",
        "    from torchsummary import summary\n",
        "\n",
        "try:\n",
        "    from torcheval.metrics.functional import multiclass_f1_score\n",
        "except:\n",
        "    !pip install torcheval\n",
        "    from torcheval.metrics.functional import multiclass_f1_score\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import os\n",
        "\n",
        "import re\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import seaborn as sn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "from torchvision.io import read_image, read_video\n",
        "\n",
        "import torchaudio\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML, Video\n",
        "\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import gc\n",
        "\n",
        "# !pip install pytorchvideo\n",
        "\n",
        "from torchvision.transforms import Compose, Lambda, RandomCrop, RandomHorizontalFlip, Resize, ToTensor, ToPILImage, CenterCrop, ColorJitter, RandomPerspective\n",
        "\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "import inspect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA-xqGb8etrG"
      },
      "source": [
        "## **Setting up environment & hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "wuLU2AIhesIg",
        "outputId": "06e3da53-466a-445f-efba-cc30d98a6de9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set up device: use GPU or CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZbD7sUOb3HR",
        "outputId": "3ee38b15-32e2-4468-aa27-192551b26d3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "    Uncomment this line if running from Google Colab\n",
        "\"\"\"\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2FgZoPCbl5p"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    torch.cuda.get_device_name(0)\n",
        "except:\n",
        "    print(\"No CUDA. CPU available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbabBic1oIG8"
      },
      "outputs": [],
      "source": [
        "# The path to the root directory of the dataset. Change this on your system\n",
        "working_dir = \"/path_to_ravdess/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBwidu3dgOw0",
        "outputId": "e583fb60-0107-44f1-e70c-bfada5e91b8e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'lr': 0.0001,\n",
              " 'epochs': 30,\n",
              " 'adam_betas': (0.98, 0.999),\n",
              " 'batch': 16,\n",
              " 'sdg_momentum': 0.99,\n",
              " 'sdg_weight_decay': 0.45,\n",
              " 'num_features': 1024,\n",
              " 'max_seq_len': 120}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Hyperparameters. Tweak as you wish\n",
        "hyperparams = {\n",
        "    \"lr\": 0.0001, # Learning Rate\n",
        "    \"epochs\": 30, # Number of Epochs\n",
        "    \"adam_betas\": (0.98, 0.999), # B1 and B2 (weight decays) of ADAM\n",
        "    \"batch\": 16, # Mini-batch size\n",
        "    \"sdg_momentum\": 0.99, # Stochastic Gradient Descent momentum\n",
        "    \"sdg_weight_decay\": 0.45, # Stochastic Gradient Descent weight decay,\n",
        "}\n",
        "\n",
        "hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5IE6J8FgOuI"
      },
      "outputs": [],
      "source": [
        "# A dict that maps the class name to our assigned index (uses: track emotion index for prediction)\n",
        "\"\"\"\n",
        "This is for RAVDESS ONLY. Migrations for SAVEE and CREMA-D will be made later\n",
        "\"\"\"\n",
        "class2idx = {\n",
        "    \"neutral\": 0,\n",
        "    \"calm\": 1,\n",
        "    \"happy\": 2,\n",
        "    \"sad\": 3,\n",
        "    \"angry\": 4,\n",
        "    \"fearful\": 5,\n",
        "    \"disgust\": 6,\n",
        "    \"surprised\": 7,\n",
        "}\n",
        "\n",
        "# A dict that maps the index to the class name (uses: decorate prediction)\n",
        "idx2class = {v:k for k,v in class2idx.items()}\n",
        "\n",
        "# A dict that maps the type given in the file name to our index(uses: dataset preparation)\n",
        "tag2idx = {\n",
        "    \"01\": 0,\n",
        "    \"02\": 1,\n",
        "    \"03\": 2,\n",
        "    \"04\": 3,\n",
        "    \"05\": 4,\n",
        "    \"06\": 5,\n",
        "    \"07\": 6,\n",
        "    \"08\": 7,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGYOIJQmgOic",
        "outputId": "66799748-dd45-40a9-ce3a-64ac90688e40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'neutral',\n",
              " 1: 'calm',\n",
              " 2: 'happy',\n",
              " 3: 'sad',\n",
              " 4: 'angry',\n",
              " 5: 'fearful',\n",
              " 6: 'disgust',\n",
              " 7: 'surprised'}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "idx2class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IB2lBwgDmL4b"
      },
      "source": [
        "## **Defining the Transforms(Augmentation Techniques) and helper functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeTNYXx0lyTk"
      },
      "outputs": [],
      "source": [
        "# Defining the transforms:\n",
        "video_frame_transform = Compose([\n",
        "    ToPILImage(),\n",
        "    Resize((252,252)),\n",
        "    CenterCrop((184,184)),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "# change frame color randomly\n",
        "video_frame_augment_color = Compose([\n",
        "    ToPILImage(),\n",
        "    Resize((252,252)),\n",
        "    CenterCrop((184,184)),\n",
        "    ColorJitter(brightness=0.4, hue=0.3, saturation=0.4),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "# change frame prespective randomly\n",
        "video_frame_augment_persp = Compose([\n",
        "    ToPILImage(),\n",
        "    Resize((252,252)),\n",
        "    CenterCrop((184,184)),\n",
        "    RandomPerspective(distortion_scale=0.3, p=1.0),\n",
        "    ToTensor()\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CHtHz0A7mgs6"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Defining the helper functions for the Audio mel-spectogram technique\n",
        "\"\"\"\n",
        "\n",
        "# Get the melspec of the audio as image/np 2d array\n",
        "def wav2melSpec(AUDIO_PATH):\n",
        "    audio, sr = librosa.load(AUDIO_PATH)\n",
        "    return librosa.feature.melspectrogram(y=audio, sr=sr)\n",
        "\n",
        "\n",
        "# Show the image spectogram\n",
        "def imgSpec(ms_feature):\n",
        "    fig, ax = plt.subplots()\n",
        "    ms_dB = librosa.power_to_db(ms_feature, ref=np.max)\n",
        "    print(ms_feature.shape)\n",
        "    img = librosa.display.specshow(ms_dB, x_axis='time', y_axis='mel', ax=ax)\n",
        "    fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
        "    ax.set(title='Mel-frequency spectrogram');\n",
        "\n",
        "# Hear the audio\n",
        "def hear_audio(AUDIO_PATH):\n",
        "    audio, sr = librosa.load(AUDIO_PATH)\n",
        "\n",
        "    print(\"\\t\", end=\"\")\n",
        "    ipd.display(ipd.Audio(data=audio, rate=sr))\n",
        "\n",
        "\n",
        "def show_video(video_path):\n",
        "    from base64 import b64encode\n",
        "\n",
        "    if os.path.isfile(video_path):\n",
        "        ext = '.mp4'\n",
        "    else:\n",
        "        print(\"Error: Please check the path.\")\n",
        "\n",
        "    video_encoded = open(video_path, \"rb\").read()\n",
        "    data = \"data:video/mp4;base64,\" + b64encode(video_encoded).decode()\n",
        "\n",
        "    video_tag = '<video width=\"400\" height=\"300\" controls alt=\"test\" src=\"%s\">' % data\n",
        "    return HTML(data=video_tag)\n",
        "\n",
        "# Show 1 example\n",
        "def show_example(video_path, audio_path, prediction=None, actual=None, save_memory=False):\n",
        "    if prediction is not None:\n",
        "        print(\"Predicted Label:\", idx2class[prediction])\n",
        "    print(\"Actual Label:\", idx2class[actual])\n",
        "\n",
        "    if save_memory is False:\n",
        "        print(\"Video path:\", video_path)\n",
        "        ipd.display(Video(video_path, embed=True, width=400, height=300))\n",
        "\n",
        "        # display(show_video(video_path))\n",
        "        print(\"Audio path:\", audio_path)\n",
        "        hear_audio(audio_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SHmBEpnbl5y"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "    Defining the helper functions for the Audio MFCC technique\n",
        "\"\"\"\n",
        "\n",
        "# audio effects\n",
        "def audio_effects(audio, sample_rate, augment=1):\n",
        "    data = None\n",
        "    if augment == 1:\n",
        "        data = librosa.effects.percussive(y=audio)\n",
        "    elif augment == 2:\n",
        "        data = librosa.effects.pitch_shift(y=audio, sr=sample_rate, n_steps=3)\n",
        "    return data\n",
        "\n",
        "\n",
        "# normalize the audio wave\n",
        "def normalize_audio(audio):\n",
        "    audio = audio / np.max(np.abs(audio))\n",
        "    return audio\n",
        "\n",
        "def feature_extractor(file, augment=0, test=False):\n",
        "\n",
        "    attempt = 0\n",
        "    while True:\n",
        "        try:\n",
        "            data, sample_rate = librosa.load(file)\n",
        "            break\n",
        "        except:\n",
        "            if attempt == 50:\n",
        "                print(\"failed trying to find audio file\", file)\n",
        "                break\n",
        "            print(\"Audio file not read. Trying again\")\n",
        "            attempt += 1\n",
        "\n",
        "#     print(data.shape)\n",
        "\n",
        "    if augment > 0:\n",
        "        data = audio_effects(data, sample_rate, augment=augment)\n",
        "\n",
        "    data = normalize_audio(data)\n",
        "\n",
        "    # zero crossing rate\n",
        "    zcr = librosa.feature.zero_crossing_rate(y=data)[0]\n",
        "    zcr /= zcr.max()\n",
        "    zcr = zcr[0:(0+128)]\n",
        "    if len(zcr) < 128:\n",
        "        zcr = librosa.util.fix_length(zcr, size=128)\n",
        "#     result=np.vstack((result, zcr))\n",
        "\n",
        "\n",
        "    # MFCC\n",
        "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=128).T, axis=0)\n",
        "    mfcc /= mfcc.max()\n",
        "#     result = np.vstack((result, mfcc))\n",
        "\n",
        "    # Root Mean Square Value\n",
        "    rms = librosa.feature.rms(y=data)[0]\n",
        "    rms /= rms.max()\n",
        "    rms = rms[0:(0+128)]\n",
        "    if len(rms) < 128:\n",
        "        rms = librosa.util.fix_length(rms, size=128)\n",
        "#     result = np.vstack((result, rms))\n",
        "\n",
        "    # MelSpectogram\n",
        "    mel = librosa.feature.melspectrogram(y=data, sr=sample_rate)\n",
        "    mel = librosa.amplitude_to_db(mel, ref = np.max)\n",
        "    mel = np.mean(mel.T, axis=0)\n",
        "    mel /= mel.sum()\n",
        "#     result = np.vstack((result, mel))\n",
        "\n",
        "    if test:\n",
        "        return_dict = {\n",
        "            \"raw\": data,\n",
        "            \"sr\": sample_rate,\n",
        "            \"zcr\": zcr,\n",
        "            \"mfcc\": mfcc,\n",
        "            \"rms\": rms,\n",
        "            \"mel\": mel\n",
        "        }\n",
        "    else:\n",
        "        return_dict = {\n",
        "            \"zcr\": zcr,\n",
        "            \"mfcc\": mfcc,\n",
        "            \"rms\": rms,\n",
        "            \"mel\": mel\n",
        "        }\n",
        "    return return_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2iAzdWbbl5z"
      },
      "outputs": [],
      "source": [
        "def dict_to_tensor(dictionary):\n",
        "    out_dict = {}\n",
        "    for item in dictionary.items():\n",
        "        if item[0] == \"sr\":\n",
        "            out_dict[item[0]] = torch.tensor(item[1]).to(device)\n",
        "        else:\n",
        "            out_dict[item[0]] = torch.from_numpy(item[1]).to(device)\n",
        "\n",
        "    return out_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3rsMw5Wj58W"
      },
      "source": [
        "<br/>\n",
        "\n",
        "---\n",
        "\n",
        "<br/>\n",
        "\n",
        "## **Dataset Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae0Y6LRzi4AI"
      },
      "outputs": [],
      "source": [
        "# Make a tuple of audio, video, labels\n",
        "def make_ds_as_list(path):\n",
        "    audio = []\n",
        "    video = []\n",
        "    labels = []\n",
        "    for dirname, _, filenames in sorted(os.walk(f\"{path}Video\")):\n",
        "        for filename in sorted(filenames):\n",
        "            video_path = os.path.join(dirname, filename)\n",
        "            label = filename.split('-')[2]\n",
        "            label = tag2idx[label]\n",
        "            video.append(video_path)\n",
        "            labels.append(label)\n",
        "\n",
        "\n",
        "    for dirname, _, filenames in sorted(os.walk(f\"{path}Audio\")):\n",
        "        for filename in sorted(filenames):\n",
        "            audio_path = os.path.join(dirname, filename)\n",
        "            audio.append(audio_path)\n",
        "\n",
        "    return audio, video, labels\n",
        "\n",
        "# Create a dataframe\n",
        "def make_dataframe(path, augment=0):\n",
        "    audio, video, labels = make_ds_as_list(path)\n",
        "    data = pd.DataFrame()\n",
        "    data['audio_path'] = audio\n",
        "    data['video_path'] = video\n",
        "    data['label'] = labels\n",
        "    data['augment'] = augment\n",
        "\n",
        "    del audio\n",
        "    del video\n",
        "    del labels\n",
        "    gc.collect()\n",
        "\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46gw50AkjxaM"
      },
      "outputs": [],
      "source": [
        "# Make the dataset\n",
        "non_augment_df = make_dataframe(working_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qznheMRZpwn_",
        "outputId": "fa14c15e-413b-41f1-aeea-6bb378b94d92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('/content/drive/MyDrive/RAVDESS Audio-Visual Datatset/Audio/Actor_01/03-01-01-01-01-01-01.wav',\n",
              " '/content/drive/MyDrive/RAVDESS Audio-Visual Datatset/Video/Actor_01/01-01-01-01-01-01-01.mp4',\n",
              " '/content/drive/MyDrive/RAVDESS Audio-Visual Datatset/Audio/Actor_01/03-01-01-01-01-01-01.wav',\n",
              " '/content/drive/MyDrive/RAVDESS Audio-Visual Datatset/Video/Actor_01/01-01-01-01-01-01-01.mp4')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "augment_1_df = non_augment_df.copy()\n",
        "augment_1_df[\"augment\"] = 1\n",
        "\n",
        "augment_2_df = non_augment_df.copy()\n",
        "augment_2_df[\"augment\"] = 2\n",
        "\n",
        "non_augment_df[\"augment\"] = 0\n",
        "\n",
        "# check an example to see if the strings/naming conventions match\n",
        "non_augment_df[\"audio_path\"][0], non_augment_df[\"video_path\"][0], augment_1_df[\"audio_path\"][0], augment_1_df[\"video_path\"][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR6vvmZTbl52"
      },
      "source": [
        "<br>\n",
        "<hr>\n",
        "\n",
        "## Data checking and testing phase"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaT-_1Qobl52"
      },
      "source": [
        "### Do the transforms work?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXJuI6cJbl53"
      },
      "source": [
        "**YES THEY DO!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftc1ACEQbl54"
      },
      "source": [
        "<br>\n",
        "<hr>\n",
        "\n",
        "#### Checking the dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IanxxfASbl54",
        "outputId": "c0c7dd92-a3bc-48b2-dc0e-143837fd3333"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-d8924b6d-f895-461a-a1bf-b4303c381b6d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio_path</th>\n",
              "      <th>video_path</th>\n",
              "      <th>label</th>\n",
              "      <th>augment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8924b6d-f895-461a-a1bf-b4303c381b6d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-fd4f5e1d-8978-4aef-a0cb-27481911d5b7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fd4f5e1d-8978-4aef-a0cb-27481911d5b7')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-fd4f5e1d-8978-4aef-a0cb-27481911d5b7 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8924b6d-f895-461a-a1bf-b4303c381b6d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8924b6d-f895-461a-a1bf-b4303c381b6d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                          audio_path  \\\n",
              "0  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "1  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "2  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "3  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "4  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "\n",
              "                                          video_path  label  augment  \n",
              "0  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      0        1  \n",
              "1  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      0        1  \n",
              "2  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      0        1  \n",
              "3  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      0        1  \n",
              "4  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      1        1  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "augment_1_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nbIKJrMxbl55",
        "outputId": "f8bdcebb-65b3-476c-a923-6eaf8d194920"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-4f19e2c0-3c96-46c0-8323-d33b497d32e7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio_path</th>\n",
              "      <th>video_path</th>\n",
              "      <th>label</th>\n",
              "      <th>augment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f19e2c0-3c96-46c0-8323-d33b497d32e7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-1a027c38-f85b-4efc-8967-ac9895cab31f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a027c38-f85b-4efc-8967-ac9895cab31f')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-1a027c38-f85b-4efc-8967-ac9895cab31f button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f19e2c0-3c96-46c0-8323-d33b497d32e7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f19e2c0-3c96-46c0-8323-d33b497d32e7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                          audio_path  \\\n",
              "0  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "1  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "2  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "3  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "4  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "\n",
              "                                          video_path  label  augment  \n",
              "0  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      0        2  \n",
              "1  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      0        2  \n",
              "2  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      0        2  \n",
              "3  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      0        2  \n",
              "4  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      1        2  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "augment_2_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kqQDeVdPbl55",
        "outputId": "f0d25313-026b-406f-819d-c5f14c3dd8da"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-e9dfa984-29e2-463c-b927-074b50f57f1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio_path</th>\n",
              "      <th>video_path</th>\n",
              "      <th>label</th>\n",
              "      <th>augment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9dfa984-29e2-463c-b927-074b50f57f1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-f61bb1b0-3918-489e-bdf1-4dafaa80b63a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f61bb1b0-3918-489e-bdf1-4dafaa80b63a')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-f61bb1b0-3918-489e-bdf1-4dafaa80b63a button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9dfa984-29e2-463c-b927-074b50f57f1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9dfa984-29e2-463c-b927-074b50f57f1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                          audio_path  \\\n",
              "0  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "1  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "2  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "3  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "4  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "\n",
              "                                          video_path  label  augment  \n",
              "0  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      0        0  \n",
              "1  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      0        0  \n",
              "2  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      0        0  \n",
              "3  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      0        0  \n",
              "4  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      1        0  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "non_augment_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "tFMkKXKybl56",
        "outputId": "59b43b99-f32f-43d7-fa49-fd4c5564625d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-82db778c-4676-40db-91e5-462285e7a721\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio_path</th>\n",
              "      <th>video_path</th>\n",
              "      <th>label</th>\n",
              "      <th>augment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>/content/drive/MyDrive/RAVDESS Audio-Visual Da...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82db778c-4676-40db-91e5-462285e7a721')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-08199114-8b4a-4e91-93fe-235fd4d5da83\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-08199114-8b4a-4e91-93fe-235fd4d5da83')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-08199114-8b4a-4e91-93fe-235fd4d5da83 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82db778c-4676-40db-91e5-462285e7a721 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82db778c-4676-40db-91e5-462285e7a721');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                          audio_path  \\\n",
              "0  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "1  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "2  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "3  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "4  /content/drive/MyDrive/RAVDESS Audio-Visual Da...   \n",
              "\n",
              "                                          video_path  label  augment  \n",
              "0  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      0        0  \n",
              "1  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      0        0  \n",
              "2  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      0        0  \n",
              "3  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      0        0  \n",
              "4  /content/drive/MyDrive/RAVDESS Audio-Visual Da...      1        0  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.concat([non_augment_df, augment_1_df, augment_2_df])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icbcM0G6bl56",
        "outputId": "444dc95f-009f-4c97-dddb-030ac7eb153d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1440, 1440, 1440, 4320)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(non_augment_df), len(augment_1_df), len(augment_2_df), len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8lyicr7nx6K"
      },
      "source": [
        "<br/>\n",
        "\n",
        "---\n",
        "\n",
        "## **Dataset Splitting**\n",
        "\n",
        "We will now split the dataset into train, cv, test splits.\n",
        "\n",
        "60:20:20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WVZ1JCxlNTC",
        "outputId": "0ad109ee-d853-4f09-ed97-b17206cc4b61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2592, 1728)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split into 60% train, 20% val, 20% test set\n",
        "train_df, test_df = train_test_split(df, test_size=0.40, shuffle=True, random_state=42)\n",
        "len(train_df), len(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "fU2NCTHRlWX6",
        "outputId": "835a3e0b-2bc1-48ab-daf6-0d8d25b6aa68"
      },
      "outputs": [],
      "source": [
        "# Check your examples\n",
        "idx = 90 # Change index to see different examples\n",
        "show_example(train_df[\"video_path\"].iloc[idx], train_df[\"audio_path\"].iloc[idx], actual=train_df[\"label\"].iloc[idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiN_jVU4oHE_"
      },
      "outputs": [],
      "source": [
        "cv_df, test_df = train_test_split(test_df, test_size=0.50, shuffle=True, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiF5Ib33oxsr",
        "outputId": "002c7f27-816a-4fd0-f8e4-92a2a0666812"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2592, 864, 864)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# View their length\n",
        "len(train_df), len(cv_df), len(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXyeRaD2ucNK",
        "outputId": "72194217-0552-426c-e46b-1765890223c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "89558"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "del df, non_augment_df, augment_1_df, augment_2_df\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TtHooQt9jzUo"
      },
      "outputs": [],
      "source": [
        "random.seed(42)\n",
        "\n",
        "# The dataset to use in the dataloader\n",
        "class RAVDESSDataset(Dataset):\n",
        "    def __init__(self, dataframe, video_frame_transform=None, video_strategy='optimal', cut_video=False, cut_audio=False):\n",
        "\n",
        "        self.cut_video = cut_video\n",
        "        self.cut_audio = cut_audio\n",
        "\n",
        "        self.examples = dataframe\n",
        "        self.video_frame_transform = {\n",
        "            0: video_frame_transform,\n",
        "            1: video_frame_augment_color,\n",
        "            2: video_frame_augment_persp\n",
        "        }\n",
        "\n",
        "\n",
        "        self.video_strategy = video_strategy\n",
        "\n",
        "        del dataframe, video_frame_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __optimal_strategy(self, video, augment=0):\n",
        "\n",
        "        frames = []\n",
        "\n",
        "        q1_point = video.shape[0] // 4\n",
        "        q2_point = video.shape[0] // 2\n",
        "        q3_point = int((video.shape[0] * (3/4)))\n",
        "        length = video.shape[0]\n",
        "\n",
        "        q1_q2_mid = int((q1_point + (q2_point - 5))//2)\n",
        "        q2_q3_mid = int((q2_point + (q3_point - 5))//2)\n",
        "\n",
        "        q1_lb = q1_point-10\n",
        "        q1_up = q1_q2_mid\n",
        "\n",
        "        q2_lb = q2_point-10\n",
        "        q2_up = q2_q3_mid\n",
        "\n",
        "        q3_lb = q3_point-10\n",
        "\n",
        "        # select random starting frames\n",
        "        frames.append(self.video_frame_transform[augment](video[q1_lb]))\n",
        "        frames.append(self.video_frame_transform[augment](video[q1_point]))\n",
        "        frames.append(self.video_frame_transform[augment](video[q1_up]))\n",
        "\n",
        "        # select random mid frames\n",
        "        frames.append(self.video_frame_transform[augment](video[q2_lb]))\n",
        "        frames.append(self.video_frame_transform[augment](video[q2_point]))\n",
        "        frames.append(self.video_frame_transform[augment](video[q2_up]))\n",
        "\n",
        "        # select random end frames\n",
        "        frames.append(self.video_frame_transform[augment](video[q3_lb]))\n",
        "        frames.append(self.video_frame_transform[augment](video[q3_point]))\n",
        "        frames.append(self.video_frame_transform[augment](video[-1]))\n",
        "\n",
        "\n",
        "        frames = torch.stack(frames)\n",
        "\n",
        "        return frames\n",
        "\n",
        "\n",
        "    def __all_strategy(self, video):\n",
        "        length = video.shape[0]\n",
        "\n",
        "        frames = []\n",
        "        for i, f in enumerate(video):\n",
        "            if i == hyperparams[\"max_seq_len\"]:\n",
        "                break\n",
        "            frame = self.video_frame_transform(f)\n",
        "            frames.append(frame)\n",
        "            del frame\n",
        "            gc.collect()\n",
        "\n",
        "\n",
        "        if length < hyperparams[\"max_seq_len\"]:\n",
        "            diff = hyperparams[\"max_seq_len\"] - length\n",
        "\n",
        "            Q2 = int(length // 2)\n",
        "            for i in range(Q2, Q2 + diff):\n",
        "                frames.append(self.video_frame_transform(video[i]))\n",
        "\n",
        "        frames = torch.stack(frames)\n",
        "        del video\n",
        "        gc.collect()\n",
        "\n",
        "        return frames\n",
        "\n",
        "\n",
        "    def __audio_extraction(self, audio, augment=0):\n",
        "        feats = feature_extractor(audio, augment)\n",
        "        return dict_to_tensor(feats)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        df = self.examples.iloc[idx]\n",
        "        audio_path, video_path, label, augment = df[\"audio_path\"], df[\"video_path\"], df[\"label\"], df['augment']\n",
        "\n",
        "        if self.cut_video == False:\n",
        "\n",
        "            attempt = 0\n",
        "            while True:\n",
        "                try:\n",
        "                    video = read_video(video_path, pts_unit='sec')[0]\n",
        "                    break\n",
        "                except:\n",
        "                    if attempt == 50:\n",
        "                        print(\"Video file can't be read\", video_path)\n",
        "                        break\n",
        "                    print(\"Video file not read. Trying again\")\n",
        "                    attempt += 1\n",
        "\n",
        "\n",
        "            video = torch.permute(video, (0,3,1,2))\n",
        "\n",
        "            if self.video_strategy == 'optimal':\n",
        "                video = self.__optimal_strategy(video, augment)\n",
        "            elif self.video_strategy == 'all':\n",
        "                video = self.__all_strategy(video)\n",
        "        else:\n",
        "            video = torch.zeros((1,1))\n",
        "\n",
        "        if self.cut_audio == False:\n",
        "            audio = self.__audio_extraction(audio_path, augment)\n",
        "        else:\n",
        "            audio = torch.zeros((1,1))\n",
        "\n",
        "\n",
        "        del df\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "        return video, audio, label, video_path, audio_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PD7KdpAjzR0"
      },
      "outputs": [],
      "source": [
        "trainds = RAVDESSDataset(train_df, video_frame_transform, video_strategy='optimal')\n",
        "cvds = RAVDESSDataset(cv_df, video_frame_transform, video_strategy='optimal')\n",
        "testds = RAVDESSDataset(test_df, video_frame_transform, video_strategy='optimal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O34tXEQvjzO3"
      },
      "outputs": [],
      "source": [
        "trainloader = DataLoader(trainds, batch_size=hyperparams[\"batch\"], shuffle=True)\n",
        "cvloader = DataLoader(cvds, batch_size=hyperparams[\"batch\"], shuffle=False)\n",
        "testloader = DataLoader(testds, batch_size=hyperparams[\"batch\"], shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO-T4pmUbl5_",
        "outputId": "90c2579b-f69d-4f15-db6c-c34943ec4d36"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "del trainds\n",
        "del cvds\n",
        "del testds\n",
        "del train_df\n",
        "del cv_df\n",
        "del test_df\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Omwz_LK5bl6R"
      },
      "outputs": [],
      "source": [
        "def view_a_loader(item, i):\n",
        "    video, audio, label, video_p, audio_p = item\n",
        "    show_example(video_p[i], audio_p[i], label[i].item(), label[i].item())\n",
        "    print(f\"Video shape: {video.shape} | Audio shape: {audio['mel'].shape}\")\n",
        "    print(f\"{video_p[i]}\")\n",
        "    for f in video[i]:\n",
        "        f = torch.permute(f, (1,2,0))\n",
        "        plt.figure(figsize=(3, 3))\n",
        "        plt.imshow(f.numpy())\n",
        "        plt.show()\n",
        "#     imgSpec(audio[i].squeeze())\n",
        "\n",
        "    del item, video, audio, label, video_p, audio_p\n",
        "    gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3WEdO8OrGE7"
      },
      "source": [
        "## **The Model**\n",
        "\n",
        "It's time to build the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A1UqmQcbl6T"
      },
      "source": [
        "### The Video Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3AfeLqtbl6U",
        "outputId": "4b36ca1b-0062-4129-f540-a258a1431518"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/r2plus1d_18-91a641e6.pth\" to /root/.cache/torch/hub/checkpoints/r2plus1d_18-91a641e6.pth\n",
            "100%|██████████| 120M/120M [00:01<00:00, 122MB/s]\n"
          ]
        }
      ],
      "source": [
        "from torchvision.models.video import r2plus1d_18\n",
        "\n",
        "R2plus1D = r2plus1d_18(weights='KINETICS400_V1').to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTAtuAoUbl6V"
      },
      "outputs": [],
      "source": [
        "from torchvision.models.video.resnet import Conv2Plus1D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4guMEY8bl6W"
      },
      "source": [
        "<hr>\n",
        "<br>\n",
        "\n",
        "\n",
        "### The Audio Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sa8NMi1rbl6Y"
      },
      "outputs": [],
      "source": [
        "class PassThrough(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blyDHcAhbl6b"
      },
      "outputs": [],
      "source": [
        "class Conv1D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv1d(1, 128, kernel_size=3, dilation=2, bias=False),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Conv1d(128, 128, kernel_size=3, dilation=2, bias=False),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.GroupNorm(1, 128)\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv1d(128, 128, kernel_size=3, dilation=2, bias=False),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Conv1d(128, 128, kernel_size=3, dilation=2, bias=False),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.GroupNorm(1, 128)\n",
        "        )\n",
        "\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv1d(128, 128, kernel_size=3, dilation=2, bias=False),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.MaxPool1d(2),\n",
        "            nn.GroupNorm(1, 128)\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqO8d9FqZegd"
      },
      "outputs": [],
      "source": [
        "class SENet(nn.Module):\n",
        "    def __init__(self, channels, reduction=16):\n",
        "        super().__init__()\n",
        "\n",
        "        self.se_net = nn.Sequential(\n",
        "            nn.Linear(channels, channels // reduction),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(channels // reduction, channels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.global_pooling_bridge = nn.AdaptiveAvgPool1d(1)\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.global_pooling_bridge(x)\n",
        "#         print(\"shape input to se net: \", out.shape)\n",
        "        out = self.flatten(out)\n",
        "        out = self.se_net(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vu5yeD7GZfPx"
      },
      "outputs": [],
      "source": [
        "class DaggerNetV2(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cnn_encoder = Conv1D()\n",
        "\n",
        "        self.se_net = SENet(channels=128)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.global_pooling = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        out = self.cnn_encoder(x)\n",
        "        residual = out\n",
        "\n",
        "\n",
        "        attn_out = self.se_net(out)\n",
        "\n",
        "\n",
        "        attn_out = attn_out.unsqueeze(dim=-1)\n",
        "\n",
        "        out_total = attn_out * residual\n",
        "\n",
        "        out_total = self.flatten(out_total)\n",
        "\n",
        "\n",
        "        return out_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFi9e5M7bl6c"
      },
      "outputs": [],
      "source": [
        "class AudioFeatureExtractor(nn.Module):\n",
        "    def __init__(self, rnn_hidden_size, rnn_num_layers):\n",
        "        super().__init__()\n",
        "\n",
        "        self.rnn_hidden_size = rnn_hidden_size\n",
        "        self.rnn_num_layers = rnn_num_layers\n",
        "\n",
        "\n",
        "        self.zcr_net = DaggerNetV2()\n",
        "        self.rms_net = DaggerNetV2()\n",
        "        self.mfcc_net = DaggerNetV2()\n",
        "        self.mel_net = DaggerNetV2()\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x[\"mfcc\"] = x[\"mfcc\"].unsqueeze(dim=1).float()\n",
        "        x[\"zcr\"] = x[\"zcr\"].unsqueeze(dim=1).float()\n",
        "        x[\"mel\"] = x[\"mel\"].unsqueeze(dim=1).float()\n",
        "        x[\"rms\"] = x[\"rms\"].unsqueeze(dim=1).float()\n",
        "\n",
        "\n",
        "\n",
        "        out_mfcc = self.mfcc_net(x[\"mfcc\"])\n",
        "        out_mel = self.mel_net(x[\"mel\"])\n",
        "\n",
        "        out_zcr = self.zcr_net(x[\"zcr\"])\n",
        "        out_rms = self.rms_net(x[\"rms\"])\n",
        "\n",
        "        combined = torch.cat([out_mfcc, out_zcr, out_rms, out_mel], dim=1)\n",
        "\n",
        "        return combined"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sfcc-gTdbl6d"
      },
      "source": [
        "<br>\n",
        "<hr>\n",
        "<br>\n",
        "\n",
        "## The Multimodal Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV5HuO1ZkMLr"
      },
      "outputs": [],
      "source": [
        "class MainMultimodal(nn.Module):\n",
        "    def __init__(self, num_classes, trainable=False, fine_tune_limit=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "#         # define video extractor, cut off FCN layer\n",
        "        self.video_extractor = R2plus1D\n",
        "\n",
        "#         # cut off layer fcn\n",
        "        self.video_extractor.fc = PassThrough()\n",
        "\n",
        "\n",
        "        # define audio extractor\n",
        "        self.audio_extractor = AudioFeatureExtractor(rnn_hidden_size=32, rnn_num_layers=1).to(device)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.LayerNorm(512 + 5632),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512 + 5632, num_classes, bias=True),\n",
        "        )\n",
        "\n",
        "        # init dual gpu usuage\n",
        "        self.video_extractor = nn.DataParallel(self.video_extractor)\n",
        "        self.audio_extractor = nn.DataParallel(self.audio_extractor)\n",
        "\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "            Set the model to trainable false\n",
        "        \"\"\"\n",
        "        if trainable is False:\n",
        "            for param in self.video_extractor.parameters():\n",
        "                param.requires_grad = False\n",
        "        else:\n",
        "\n",
        "            \"\"\"\n",
        "                Train all layers\n",
        "            \"\"\"\n",
        "            if fine_tune_limit == 'all':\n",
        "                for param in self.video_extractor.parameters():\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            else:\n",
        "                \"\"\"\n",
        "                    Set the fine tune limits\n",
        "                \"\"\"\n",
        "                count = 0 # keep track for layer count\n",
        "                length = sum(1 for _ in self.video_extractor.children()) # get the length of layers\n",
        "                limit = length - fine_tune_limit # set the limit [if length is 7, then limit = 7-2(default) = 5 ---> if count is = or above this we set to trainable ]\n",
        "\n",
        "\n",
        "                for child in self.video_extractor.module.children():\n",
        "                    if count >= limit:\n",
        "                        for param in child.parameters():\n",
        "                            param.requires_grad = True\n",
        "                    else:\n",
        "                        for param in child.parameters():\n",
        "                            param.requires_grad = False\n",
        "\n",
        "                    count += 1\n",
        "\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "\n",
        "    def forward(self, video, audio):\n",
        "\n",
        "        video = torch.permute(video, (0,2,1,3,4))\n",
        "\n",
        "\n",
        "        video_feature_values = self.video_extractor(video)\n",
        "\n",
        "        audio_feature_values = self.audio_extractor(audio)\n",
        "\n",
        "\n",
        "        del video, audio\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "        combined = torch.cat([video_feature_values, audio_feature_values], dim=1)\n",
        "\n",
        "        out_logits = self.fc(combined)\n",
        "        out_softmax = self.softmax(out_logits)\n",
        "\n",
        "\n",
        "        return out_logits, out_softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cwFz_w-JrG4"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "modelV1 = MainMultimodal(len(idx2class), trainable=True, fine_tune_limit=3).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82mWAMMGbl6f",
        "outputId": "269a6beb-c4e8-4b43-a58a-24e68d6d84b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MainMultimodal(\n",
              "  (video_extractor): DataParallel(\n",
              "    (module): VideoResNet(\n",
              "      (stem): R2Plus1dStem(\n",
              "        (0): Conv3d(3, 45, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
              "        (1): BatchNorm3d(45, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv3d(45, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "        (4): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "      (layer1): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Sequential(\n",
              "            (0): Conv2Plus1D(\n",
              "              (0): Conv3d(64, 144, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "              (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "              (3): Conv3d(144, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "            )\n",
              "            (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Sequential(\n",
              "            (0): Conv2Plus1D(\n",
              "              (0): Conv3d(64, 144, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "              (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "              (3): Conv3d(144, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "            )\n",
              "            (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Sequential(\n",
              "            (0): Conv2Plus1D(\n",
              "              (0): Conv3d(64, 144, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "              (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "              (3): Conv3d(144, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "            )\n",
              "            (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Sequential(\n",
              "            (0): Conv2Plus1D(\n",
              "              (0): Conv3d(64, 144, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "              (1): BatchNorm3d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "              (3): Conv3d(144, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "            )\n",
              "            (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer2): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Sequential(\n",
              "            (0): Conv2Plus1D(\n",
              "              (0): Conv3d(64, 230, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "              (1): BatchNorm3d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "              (3): Conv3d(230, 128, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "            )\n",
              "            (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Sequential(\n",
              "            (0): Conv2Plus1D(\n",
              "              (0): Conv3d(128, 230, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "              (1): BatchNorm3d(230, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "              (3): Conv3d(230, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "            )\n",
              "            (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
              "            (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Sequential(\n",
              "            (0): Conv2Plus1D(\n",
              "              (0): Conv3d(128, 288, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "              (1): BatchNorm3d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "              (3): Conv3d(288, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "            )\n",
              "            (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Sequential(\n",
              "            (0): Conv2Plus1D(\n",
              "              (0): Conv3d(128, 288, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "              (1): BatchNorm3d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "              (3): Conv3d(288, 128, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "            )\n",
              "            (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer3): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Sequential(\n",
              "            (0): Conv2Plus1D(\n",
              "              (0): Conv3d(128, 460, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "              (1): BatchNorm3d(460, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "              (3): Conv3d(460, 256, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "            )\n",
              "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Sequential(\n",
              "            (0): Conv2Plus1D(\n",
              "              (0): Conv3d(256, 460, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "              (1): BatchNorm3d(460, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "              (3): Conv3d(460, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "            )\n",
              "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
              "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Sequential(\n",
              "            (0): Conv2Plus1D(\n",
              "              (0): Conv3d(256, 576, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "              (1): BatchNorm3d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "              (3): Conv3d(576, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "            )\n",
              "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Sequential(\n",
              "            (0): Conv2Plus1D(\n",
              "              (0): Conv3d(256, 576, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "              (1): BatchNorm3d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "              (3): Conv3d(576, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "            )\n",
              "            (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (layer4): Sequential(\n",
              "        (0): BasicBlock(\n",
              "          (conv1): Sequential(\n",
              "            (0): Conv2Plus1D(\n",
              "              (0): Conv3d(256, 921, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
              "              (1): BatchNorm3d(921, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "              (3): Conv3d(921, 512, kernel_size=(3, 1, 1), stride=(2, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "            )\n",
              "            (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Sequential(\n",
              "            (0): Conv2Plus1D(\n",
              "              (0): Conv3d(512, 921, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "              (1): BatchNorm3d(921, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "              (3): Conv3d(921, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "            )\n",
              "            (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (relu): ReLU(inplace=True)\n",
              "          (downsample): Sequential(\n",
              "            (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
              "            (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): BasicBlock(\n",
              "          (conv1): Sequential(\n",
              "            (0): Conv2Plus1D(\n",
              "              (0): Conv3d(512, 1152, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "              (1): BatchNorm3d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "              (3): Conv3d(1152, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "            )\n",
              "            (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Sequential(\n",
              "            (0): Conv2Plus1D(\n",
              "              (0): Conv3d(512, 1152, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
              "              (1): BatchNorm3d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              (2): ReLU(inplace=True)\n",
              "              (3): Conv3d(1152, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
              "            )\n",
              "            (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "          (relu): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
              "      (fc): PassThrough()\n",
              "    )\n",
              "  )\n",
              "  (audio_extractor): DataParallel(\n",
              "    (module): AudioFeatureExtractor(\n",
              "      (zcr_net): DaggerNetV2(\n",
              "        (cnn_encoder): Conv1D(\n",
              "          (conv1): Sequential(\n",
              "            (0): Conv1d(1, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.3, inplace=False)\n",
              "            (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (4): GELU(approximate='none')\n",
              "            (5): Dropout(p=0.3, inplace=False)\n",
              "            (6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "            (7): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          )\n",
              "          (conv2): Sequential(\n",
              "            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.3, inplace=False)\n",
              "            (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (4): GELU(approximate='none')\n",
              "            (5): Dropout(p=0.3, inplace=False)\n",
              "            (6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "            (7): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          )\n",
              "          (conv3): Sequential(\n",
              "            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.3, inplace=False)\n",
              "            (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "            (4): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          )\n",
              "        )\n",
              "        (se_net): SENet(\n",
              "          (se_net): Sequential(\n",
              "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
              "            (1): ReLU()\n",
              "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
              "            (3): Sigmoid()\n",
              "          )\n",
              "          (global_pooling_bridge): AdaptiveAvgPool1d(output_size=1)\n",
              "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "        )\n",
              "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "        (global_pooling): AdaptiveAvgPool1d(output_size=1)\n",
              "      )\n",
              "      (rms_net): DaggerNetV2(\n",
              "        (cnn_encoder): Conv1D(\n",
              "          (conv1): Sequential(\n",
              "            (0): Conv1d(1, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.3, inplace=False)\n",
              "            (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (4): GELU(approximate='none')\n",
              "            (5): Dropout(p=0.3, inplace=False)\n",
              "            (6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "            (7): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          )\n",
              "          (conv2): Sequential(\n",
              "            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.3, inplace=False)\n",
              "            (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (4): GELU(approximate='none')\n",
              "            (5): Dropout(p=0.3, inplace=False)\n",
              "            (6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "            (7): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          )\n",
              "          (conv3): Sequential(\n",
              "            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.3, inplace=False)\n",
              "            (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "            (4): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          )\n",
              "        )\n",
              "        (se_net): SENet(\n",
              "          (se_net): Sequential(\n",
              "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
              "            (1): ReLU()\n",
              "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
              "            (3): Sigmoid()\n",
              "          )\n",
              "          (global_pooling_bridge): AdaptiveAvgPool1d(output_size=1)\n",
              "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "        )\n",
              "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "        (global_pooling): AdaptiveAvgPool1d(output_size=1)\n",
              "      )\n",
              "      (mfcc_net): DaggerNetV2(\n",
              "        (cnn_encoder): Conv1D(\n",
              "          (conv1): Sequential(\n",
              "            (0): Conv1d(1, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.3, inplace=False)\n",
              "            (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (4): GELU(approximate='none')\n",
              "            (5): Dropout(p=0.3, inplace=False)\n",
              "            (6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "            (7): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          )\n",
              "          (conv2): Sequential(\n",
              "            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.3, inplace=False)\n",
              "            (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (4): GELU(approximate='none')\n",
              "            (5): Dropout(p=0.3, inplace=False)\n",
              "            (6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "            (7): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          )\n",
              "          (conv3): Sequential(\n",
              "            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.3, inplace=False)\n",
              "            (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "            (4): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          )\n",
              "        )\n",
              "        (se_net): SENet(\n",
              "          (se_net): Sequential(\n",
              "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
              "            (1): ReLU()\n",
              "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
              "            (3): Sigmoid()\n",
              "          )\n",
              "          (global_pooling_bridge): AdaptiveAvgPool1d(output_size=1)\n",
              "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "        )\n",
              "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "        (global_pooling): AdaptiveAvgPool1d(output_size=1)\n",
              "      )\n",
              "      (mel_net): DaggerNetV2(\n",
              "        (cnn_encoder): Conv1D(\n",
              "          (conv1): Sequential(\n",
              "            (0): Conv1d(1, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.3, inplace=False)\n",
              "            (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (4): GELU(approximate='none')\n",
              "            (5): Dropout(p=0.3, inplace=False)\n",
              "            (6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "            (7): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          )\n",
              "          (conv2): Sequential(\n",
              "            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.3, inplace=False)\n",
              "            (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (4): GELU(approximate='none')\n",
              "            (5): Dropout(p=0.3, inplace=False)\n",
              "            (6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "            (7): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          )\n",
              "          (conv3): Sequential(\n",
              "            (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), dilation=(2,), bias=False)\n",
              "            (1): GELU(approximate='none')\n",
              "            (2): Dropout(p=0.3, inplace=False)\n",
              "            (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "            (4): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
              "          )\n",
              "        )\n",
              "        (se_net): SENet(\n",
              "          (se_net): Sequential(\n",
              "            (0): Linear(in_features=128, out_features=8, bias=True)\n",
              "            (1): ReLU()\n",
              "            (2): Linear(in_features=8, out_features=128, bias=True)\n",
              "            (3): Sigmoid()\n",
              "          )\n",
              "          (global_pooling_bridge): AdaptiveAvgPool1d(output_size=1)\n",
              "          (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "        )\n",
              "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "        (global_pooling): AdaptiveAvgPool1d(output_size=1)\n",
              "      )\n",
              "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "      (softmax): Softmax(dim=1)\n",
              "    )\n",
              "  )\n",
              "  (fc): Sequential(\n",
              "    (0): LayerNorm((6144,), eps=1e-05, elementwise_affine=True)\n",
              "    (1): Dropout(p=0.5, inplace=False)\n",
              "    (2): Linear(in_features=6144, out_features=8, bias=True)\n",
              "  )\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelV1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njefzEopbl6g"
      },
      "outputs": [],
      "source": [
        "# next(modelV1.parameters()).is_cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hh67CLS0KP4p"
      },
      "outputs": [],
      "source": [
        "optim = torch.optim.AdamW(params=modelV1.parameters(), lr=hyperparams[\"lr\"], betas=hyperparams[\"adam_betas\"], weight_decay=1e-2)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZaA9yP7J6DE"
      },
      "outputs": [],
      "source": [
        "def train_step(model: torch.nn.Module, dataloader, optimizer, loss_fn, accuracy_fn=None, save_memory=False):\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch, (videos, audios, labels, video_paths, audio_paths) in enumerate(dataloader):\n",
        "        labels = labels.type(torch.LongTensor)\n",
        "        videos, labels = videos.to(device), labels.to(device)\n",
        "\n",
        "        y_logits, y_softmax = model(videos, audios)\n",
        "        y_logits, y_softmax = y_logits.to(device), y_softmax.to(device)\n",
        "\n",
        "        # print(y_logits.shape)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        preds = y_softmax.argmax(dim=1).to(device)\n",
        "        videos = videos.detach().cpu()\n",
        "        # audios = audios.detach().cpu()\n",
        "        del videos, audios\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "        # print(labels.shape, preds.shape)\n",
        "\n",
        "        loss = loss_fn(y_logits, labels)\n",
        "        acc = accuracy_fn(preds, labels, num_classes=len(idx2class))\n",
        "        train_loss += loss.item()\n",
        "        train_acc += acc\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        if batch == 0 or batch == len(dataloader) - 1:\n",
        "            sample = random.randint(1, y_logits.shape[0])-1\n",
        "            print(f\"Batch: #{batch} | Train Loss: {loss} | Train Accuracy: {acc}\")\n",
        "            show_example(video_paths[sample], audio_paths[sample], preds[sample].detach().cpu().item(), labels[sample].detach().cpu().item(), save_memory)\n",
        "\n",
        "        del labels\n",
        "        del video_paths\n",
        "        del audio_paths\n",
        "        preds = preds.detach().cpu()\n",
        "        del preds\n",
        "        y_logits = y_logits.detach().cpu()\n",
        "        del y_logits\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "\n",
        "    train_loss /= len(dataloader)\n",
        "    train_acc /= len(dataloader)\n",
        "    print(f\"Total Train loss: {train_loss} | Total Train accuracy: {train_acc}\")\n",
        "    return train_loss, train_acc\n",
        "\n",
        "\n",
        "def eval_step(model: torch.nn.Module, dataloader, loss_fn, accuracy_fn=None, save_memory=False, confusion_matrix=False):\n",
        "    eval_loss = 0.0\n",
        "    eval_acc = 0.0\n",
        "\n",
        "    y_true = []\n",
        "    y_preds = []\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch, (videos, audios, labels, video_paths, audio_paths) in enumerate(dataloader):\n",
        "            labels = labels.type(torch.LongTensor)\n",
        "            videos, labels = videos.to(device), labels.to(device)\n",
        "\n",
        "            y_logits, y_softmax = model(videos, audios)\n",
        "            y_logits, y_softmax = y_logits.to(device), y_softmax.to(device)\n",
        "\n",
        "            preds = y_softmax.argmax(dim=1).to(device)\n",
        "\n",
        "            if confusion_matrix:\n",
        "                y_preds.extend(preds.detach().cpu().numpy())\n",
        "                y_true.extend(labels.detach().cpu().numpy())\n",
        "\n",
        "            videos = videos.detach().cpu()\n",
        "            # audios = audios.detach().cpu()\n",
        "            del videos, audios\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "\n",
        "            loss = loss_fn(y_logits, labels)\n",
        "            acc = accuracy_fn(preds, labels, num_classes=len(idx2class))\n",
        "            eval_loss += loss.item()\n",
        "            eval_acc += acc\n",
        "\n",
        "\n",
        "            if batch == 0 or batch == len(dataloader) - 1:\n",
        "                sample = random.randint(1, y_logits.shape[0])-1\n",
        "                print(f\"Batch: #{batch} | Eval. Loss: {loss} | Eval. Accuracy: {acc}\")\n",
        "                show_example(video_paths[sample], audio_paths[sample], preds[sample].detach().cpu().item(), labels[sample].detach().cpu().item(), save_memory)\n",
        "\n",
        "            del labels\n",
        "            del video_paths\n",
        "            del audio_paths\n",
        "            preds = preds.detach().cpu()\n",
        "            del preds\n",
        "            y_logits = y_logits.detach().cpu()\n",
        "            del y_logits\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "\n",
        "        eval_loss /= len(dataloader)\n",
        "        eval_acc /= len(dataloader)\n",
        "\n",
        "    print(f\"Total Eval. Loss: {eval_loss} | Total Eval. Accuracy: {eval_acc}\")\n",
        "\n",
        "    if confusion_matrix:\n",
        "        return eval_loss, eval_acc, y_true, y_preds\n",
        "    else:\n",
        "        return eval_loss, eval_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFW2EX8Nbl6j",
        "outputId": "f12b918a-5f2d-4142-ed18-1bce449cf3a5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-52-50d27bdd0faf>:1: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "from tqdm.autonotebook import tqdm\n",
        "import time\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWfBz3SBbl6j"
      },
      "outputs": [],
      "source": [
        "epochs = []\n",
        "train_loss_history = []\n",
        "eval_loss_history = []\n",
        "\n",
        "train_accuracy_history = []\n",
        "eval_accuracy_history = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCb7QSi5bl6k"
      },
      "outputs": [],
      "source": [
        "best_params = {}\n",
        "best_train_loss, best_eval_loss = 10000, 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x36S97zpL1Ak"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "save_memory = True\n",
        "\n",
        "if save_memory:\n",
        "    print(\"\\tSave memory mode is on. Set `save_memory=False` to see video-audio examples\")\n",
        "\n",
        "start = time.time()\n",
        "for epoch in range(hyperparams['epochs']):\n",
        "    print(f\"========================== Starting Epoch: # {epoch} ==========================\")\n",
        "\n",
        "    inference_start = time.time()\n",
        "\n",
        "    train_loss, train_acc = train_step(modelV1, trainloader, optim, loss_fn, multiclass_f1_score, save_memory=save_memory)\n",
        "    eval_loss, eval_acc = eval_step(modelV1, cvloader, loss_fn, multiclass_f1_score, save_memory=save_memory)\n",
        "\n",
        "    inference_total = time.time() - inference_start\n",
        "    convert_inf = str(datetime.timedelta(seconds=inference_total))\n",
        "\n",
        "\n",
        "    print(f\"Epoch: #{epoch} | Total Train Loss: {train_loss} | Total Eval. Loss: {eval_loss} | Train Acc: {train_acc * 100}% | Eval Acc: {eval_acc * 100}% in {convert_inf}\")\n",
        "\n",
        "\n",
        "    epochs.append(epoch+1)\n",
        "    train_loss_history.append(train_loss)\n",
        "    eval_loss_history.append(eval_loss)\n",
        "    train_accuracy_history.append(train_acc.detach().cpu()*100)\n",
        "    eval_accuracy_history.append(eval_acc.detach().cpu()*100)\n",
        "\n",
        "    if train_loss < best_train_loss and eval_loss < best_eval_loss:\n",
        "        best_train_loss, best_eval_loss = train_loss, eval_loss\n",
        "        torch.save(modelV1.state_dict(), \"./best-multimodal.pt\")\n",
        "        best_w = modelV1.state_dict()\n",
        "\n",
        "    del train_loss, eval_loss, train_acc, eval_acc\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRIwKJd2bl6l"
      },
      "outputs": [],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bL7zVWAJKoZA"
      },
      "outputs": [],
      "source": [
        "torch.save(modelV1.state_dict(), \"./multimodal-final.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Prr5Tsibl6m"
      },
      "outputs": [],
      "source": [
        "# epoch = hyperparams[\"epochs\"]\n",
        "epoch = len(epochs)\n",
        "\n",
        "plt.plot(epochs, train_loss_history, color='dodgerblue', label='Train Loss')\n",
        "plt.plot(epochs, eval_loss_history, color='orange', label='Eval. Loss')\n",
        "\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss Value\")\n",
        "plt.title(f\"Train and Eval. Loss along {epoch} epochs (RAVDESS)\")\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.savefig(\"./Loss curves.png\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sLHCcmpBbl6n"
      },
      "outputs": [],
      "source": [
        "plt.plot(epochs, train_accuracy_history, color='dodgerblue', label='Train Accuracy')\n",
        "plt.plot(epochs, eval_accuracy_history, color='orange', label='Eval. Accuracy')\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"F1 Score Value\")\n",
        "plt.title(f\"Train and Eval. Accuracy along {epoch} epochs (RAVDESS)\")\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "\n",
        "plt.savefig(\"./F1-Score curves.png\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bdr8tCLIbl6p"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "for params in modelV1.parameters():\n",
        "    count +=1\n",
        "\n",
        "print(f\"There are {count} parameters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 996
        },
        "id": "CcqkbFj4bl6p",
        "outputId": "52b18465-de10-40fa-89c0-bf169d4d0486"
      },
      "outputs": [],
      "source": [
        "# load best weights model\n",
        "modelV1.load_state_dict(torch.load('./best-multimodal.pt'))\n",
        "\n",
        "\n",
        "test_loss, test_acc, y_true, y_preds = eval_step(modelV1, testloader, loss_fn, multiclass_f1_score, save_memory=False, confusion_matrix=True)\n",
        "test_acc = test_acc.detach().cpu()\n",
        "\n",
        "print(f\"Test loss: {test_loss}\\tTest Accuracy: {test_acc*100}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHaY50qZlC0t"
      },
      "outputs": [],
      "source": [
        "def format_margins(ax, x=0.05, y=0.05):\n",
        "    xlim = ax.get_xlim()\n",
        "    ylim = ax.get_ylim()\n",
        "\n",
        "    xmargin = (xlim[1]-xlim[0])*x\n",
        "    ymargin = (ylim[1]-ylim[0])*y\n",
        "\n",
        "    ax.set_xlim(xlim[0]-xmargin,xlim[1]+xmargin)\n",
        "    ax.set_ylim(ylim[0]-ymargin,ylim[1]+ymargin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "M7Gd_x1VuESp",
        "outputId": "535c8233-f086-40a5-c13c-780c548fcab0"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x700 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "classes = [v for k,v in idx2class.items()]\n",
        "\n",
        "cf_matrix = confusion_matrix(y_true, y_preds)\n",
        "\n",
        "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes], columns = [i for i in classes])\n",
        "\n",
        "plt.figure(figsize = (12,7))\n",
        "\n",
        "s = sn.heatmap(df_cm, annot=True, cmap='Blues', fmt=\".2f\")\n",
        "\n",
        "plt.xlabel('Predicted Label', fontsize=14, labelpad=20, fontweight='bold')\n",
        "\n",
        "plt.ylabel('True Label', fontsize=14, labelpad=20, fontweight='bold')\n",
        "\n",
        "# format_margins(s, x=0.1)\n",
        "\n",
        "plt.savefig('./confusion_matrix_ravdess.png')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "d5MVORi3bv99",
        "outputId": "390fc13f-3fe3-42e6-9e31-e61fd6f51fe9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-baa7aa8f-5bbd-4345-aae4-82ed0752a68a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "      <th>support</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9310</td>\n",
              "      <td>0.9643</td>\n",
              "      <td>58.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>calm</th>\n",
              "      <td>0.9835</td>\n",
              "      <td>0.9754</td>\n",
              "      <td>0.9794</td>\n",
              "      <td>122.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>happy</th>\n",
              "      <td>0.9636</td>\n",
              "      <td>0.9907</td>\n",
              "      <td>0.9770</td>\n",
              "      <td>107.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sad</th>\n",
              "      <td>0.9636</td>\n",
              "      <td>0.9550</td>\n",
              "      <td>0.9593</td>\n",
              "      <td>111.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>angry</th>\n",
              "      <td>0.9737</td>\n",
              "      <td>0.9911</td>\n",
              "      <td>0.9823</td>\n",
              "      <td>112.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fearful</th>\n",
              "      <td>0.9675</td>\n",
              "      <td>0.9835</td>\n",
              "      <td>0.9754</td>\n",
              "      <td>121.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disgust</th>\n",
              "      <td>0.9913</td>\n",
              "      <td>0.9744</td>\n",
              "      <td>0.9828</td>\n",
              "      <td>117.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>surprised</th>\n",
              "      <td>0.9402</td>\n",
              "      <td>0.9483</td>\n",
              "      <td>0.9442</td>\n",
              "      <td>116.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.9711</td>\n",
              "      <td>0.9711</td>\n",
              "      <td>0.9711</td>\n",
              "      <td>0.9711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.9729</td>\n",
              "      <td>0.9687</td>\n",
              "      <td>0.9706</td>\n",
              "      <td>864.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.9713</td>\n",
              "      <td>0.9711</td>\n",
              "      <td>0.9710</td>\n",
              "      <td>864.0000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-baa7aa8f-5bbd-4345-aae4-82ed0752a68a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-673bfec7-48fe-494a-b949-30142891eb50\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-673bfec7-48fe-494a-b949-30142891eb50')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-673bfec7-48fe-494a-b949-30142891eb50 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-baa7aa8f-5bbd-4345-aae4-82ed0752a68a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-baa7aa8f-5bbd-4345-aae4-82ed0752a68a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "              precision  recall  f1-score   support\n",
              "neutral          1.0000  0.9310    0.9643   58.0000\n",
              "calm             0.9835  0.9754    0.9794  122.0000\n",
              "happy            0.9636  0.9907    0.9770  107.0000\n",
              "sad              0.9636  0.9550    0.9593  111.0000\n",
              "angry            0.9737  0.9911    0.9823  112.0000\n",
              "fearful          0.9675  0.9835    0.9754  121.0000\n",
              "disgust          0.9913  0.9744    0.9828  117.0000\n",
              "surprised        0.9402  0.9483    0.9442  116.0000\n",
              "accuracy         0.9711  0.9711    0.9711    0.9711\n",
              "macro avg        0.9729  0.9687    0.9706  864.0000\n",
              "weighted avg     0.9713  0.9711    0.9710  864.0000"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "report = classification_report(y_true, y_preds, target_names=[v for k,v in idx2class.items()], output_dict=True)\n",
        "\n",
        "df = pd.DataFrame(report).transpose()\n",
        "\n",
        "\n",
        "df = df.round(decimals=4)\n",
        "\n",
        "df.to_csv('./classification_report.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GLhygd0c2sQ"
      },
      "outputs": [],
      "source": [
        "# # Save stats\n",
        "# with open(\"./recorded.txt\", \"w\") as f:\n",
        "#     f.write(\"R2plus1D & CNN+SE net attempt RAVDESS\\n\")\n",
        "#     for i, line in enumerate(epochs):\n",
        "#         f.write(f\"Epoch: {line}: | Train Loss: {train_loss_history[i]} | Train Accuracy: {train_accuracy_history[i]} | Eval Loss: {eval_loss_history[i]} | Eval Accuracy: {eval_accuracy_history[i]}\")\n",
        "#         f.write(\"\\n\")\n",
        "\n",
        "#     f.write(\"\\n==================================================\\n\")\n",
        "#     f.write(f\"On best weights => Test loss: {test_loss}\\tTest Accuracy: {test_acc*100}\")\n",
        "#     f.write(\"\\n==================================================\\n\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "379Pvomcfxas"
      },
      "source": [
        "## **Citations**\n",
        "\n",
        "1. Livingstone SR, Russo FA (2018) The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English. PLoS ONE 13(5): e0196391. https://doi.org/10.1371/journal.pone.0196391"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
