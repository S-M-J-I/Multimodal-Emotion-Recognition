{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08f40c45",
   "metadata": {
    "id": "4lR0lWYje5kX",
    "papermill": {
     "duration": 0.044714,
     "end_time": "2024-09-19T03:38:35.861614",
     "exception": false,
     "start_time": "2024-09-19T03:38:35.816900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Emotion Recognition using Multimodal Deep Learning Approaches**\n",
    "\n",
    "In this experiment we propose a novel Multimodal Architecture to predict 8 different human emotions. We use audio and video as inputs to our model. The dataset this notebook runs on is the SAVEE datatset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb90469",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:38:35.939651Z",
     "iopub.status.busy": "2024-09-19T03:38:35.938211Z",
     "iopub.status.idle": "2024-09-19T03:39:52.499101Z",
     "shell.execute_reply": "2024-09-19T03:39:52.497373Z"
    },
    "executionInfo": {
     "elapsed": 18750,
     "status": "ok",
     "timestamp": 1689170732129,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "ibhyWildbSQ4",
    "outputId": "a1db7786-237d-4301-afe5-4470e106498d",
    "papermill": {
     "duration": 76.605079,
     "end_time": "2024-09-19T03:39:52.502699",
     "exception": false,
     "start_time": "2024-09-19T03:38:35.897620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install av\n",
    "\n",
    "try:\n",
    "    from torchsummary import summary\n",
    "except:\n",
    "    !pip install torchsummary\n",
    "    from torchsummary import summary\n",
    "\n",
    "try:\n",
    "    from torcheval.metrics.functional import multiclass_f1_score\n",
    "except:\n",
    "    !pip install torcheval\n",
    "    from torcheval.metrics.functional import multiclass_f1_score\n",
    "\n",
    "try:\n",
    "    import skvideo.io\n",
    "except:\n",
    "    !pip install sk-video\n",
    "    import skvideo.io\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import seaborn as sn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import read_image, read_video\n",
    "\n",
    "import torchaudio\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML, Video\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import gc\n",
    "\n",
    "# !pip install pytorchvideo\n",
    "\n",
    "from torchvision.transforms import Compose, Lambda, RandomCrop, RandomHorizontalFlip, Resize, ToTensor, ToPILImage, CenterCrop, ColorJitter, RandomPerspective\n",
    "\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93fe363",
   "metadata": {
    "id": "oA-xqGb8etrG",
    "papermill": {
     "duration": 0.041627,
     "end_time": "2024-09-19T03:39:52.583533",
     "exception": false,
     "start_time": "2024-09-19T03:39:52.541906",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Setting up environment & hyperparameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b8e1df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:39:52.837053Z",
     "iopub.status.busy": "2024-09-19T03:39:52.836599Z",
     "iopub.status.idle": "2024-09-19T03:39:56.541561Z",
     "shell.execute_reply": "2024-09-19T03:39:56.539659Z"
    },
    "papermill": {
     "duration": 3.748069,
     "end_time": "2024-09-19T03:39:56.545327",
     "exception": false,
     "start_time": "2024-09-19T03:39:52.797258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import wandb\n",
    "    wandb.login()\n",
    "except:\n",
    "    !pip install wandb -q\n",
    "    import wandb\n",
    "    wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd6eba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:39:56.630034Z",
     "iopub.status.busy": "2024-09-19T03:39:56.628769Z",
     "iopub.status.idle": "2024-09-19T03:39:56.640016Z",
     "shell.execute_reply": "2024-09-19T03:39:56.638082Z"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1689170732130,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "wuLU2AIhesIg",
    "outputId": "06e3da53-466a-445f-efba-cc30d98a6de9",
    "papermill": {
     "duration": 0.059384,
     "end_time": "2024-09-19T03:39:56.643818",
     "exception": false,
     "start_time": "2024-09-19T03:39:56.584434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up device: use GPU or CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b4a182",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:39:56.821830Z",
     "iopub.status.busy": "2024-09-19T03:39:56.821314Z",
     "iopub.status.idle": "2024-09-19T03:39:56.829077Z",
     "shell.execute_reply": "2024-09-19T03:39:56.827504Z"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1689170758200,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "X2FgZoPCbl5p",
    "papermill": {
     "duration": 0.055554,
     "end_time": "2024-09-19T03:39:56.832568",
     "exception": false,
     "start_time": "2024-09-19T03:39:56.777014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    torch.cuda.get_device_name(0)\n",
    "except:\n",
    "    print(\"No CUDA. CPU available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4c4306",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:39:56.920869Z",
     "iopub.status.busy": "2024-09-19T03:39:56.919838Z",
     "iopub.status.idle": "2024-09-19T03:39:56.926332Z",
     "shell.execute_reply": "2024-09-19T03:39:56.924682Z"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1689170758201,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "QbabBic1oIG8",
    "papermill": {
     "duration": 0.055549,
     "end_time": "2024-09-19T03:39:56.929645",
     "exception": false,
     "start_time": "2024-09-19T03:39:56.874096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The path to the root directory of the dataset. Change this on your system\n",
    "working_dir = \"/kaggle/input/cremad/CREMA-D/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6007a28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:39:57.009657Z",
     "iopub.status.busy": "2024-09-19T03:39:57.008291Z",
     "iopub.status.idle": "2024-09-19T03:39:57.019909Z",
     "shell.execute_reply": "2024-09-19T03:39:57.018424Z"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1689170758203,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "jBwidu3dgOw0",
    "outputId": "e583fb60-0107-44f1-e70c-bfada5e91b8e",
    "papermill": {
     "duration": 0.055375,
     "end_time": "2024-09-19T03:39:57.023585",
     "exception": false,
     "start_time": "2024-09-19T03:39:56.968210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters. Tweak as you wish\n",
    "hyperparams = {\n",
    "    \"lr\": 0.0001, # Learning Rate\n",
    "    \"epochs\": 30, # Number of Epochs\n",
    "    \"adam_betas\": (0.98, 0.999), # B1 and B2 (weight decays) of ADAM\n",
    "    \"batch\": 16, # Mini-batch size\n",
    "    \"sdg_momentum\": 0.99, # Stochastic Gradient Descent momentum\n",
    "    \"sdg_weight_decay\": 0.45, # Stochastic Gradient Descent weight decay,\n",
    "    \"num_features\": 1024, # the no. of feature maps we will divide the image into\n",
    "    \"max_seq_len\": 120\n",
    "}\n",
    "\n",
    "hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb505d0c",
   "metadata": {
    "id": "Le0FxaZBh2wi",
    "papermill": {
     "duration": 0.038952,
     "end_time": "2024-09-19T03:39:57.104636",
     "exception": false,
     "start_time": "2024-09-19T03:39:57.065684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br/>\n",
    "\n",
    "As stated by RAVDESS: \\\n",
    "\n",
    "File naming convention\n",
    "\n",
    "Each of the 1440 files has a unique filename. The filename consists of a 1-aprt numerical identifier (e.g., s03.wav). These identifiers define the stimulus characteristics:\n",
    "\n",
    "Filename identifiers:\n",
    "\n",
    "Audio files consist of audio WAV files sampled at 44.1 kHz\n",
    "\n",
    "There are 15 sentences for each of the 7 emotion categories.\n",
    "The initial letter(s) of the file name represents the emotion class, and the following digits represent the sentence number.\n",
    "The letters 'a', 'd', 'f', 'h', 'n', 'sa' and 'su' represent 'anger', 'disgust', 'fear', 'happiness', 'neutral', 'sadness' and 'surprise' emotion classes respectively.\n",
    "\n",
    "\n",
    "E.g., 'd03.wav' is the 3rd disgust sentence audio. \\\n",
    "E.g., 'd03.avi' is the 3rd disgust sentence video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9bbd82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:39:57.186238Z",
     "iopub.status.busy": "2024-09-19T03:39:57.185120Z",
     "iopub.status.idle": "2024-09-19T03:39:57.194507Z",
     "shell.execute_reply": "2024-09-19T03:39:57.192744Z"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1689170758204,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "A5IE6J8FgOuI",
    "papermill": {
     "duration": 0.054628,
     "end_time": "2024-09-19T03:39:57.197659",
     "exception": false,
     "start_time": "2024-09-19T03:39:57.143031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A dict that maps the class name to our assigned index (uses: track emotion index for prediction)\n",
    "class2idx = {\n",
    "    \"anger\": 0,\n",
    "    \"disgust\": 1,\n",
    "    \"fear\": 2,\n",
    "    \"happy\": 3,\n",
    "    \"neutral\": 4,\n",
    "    \"sad\": 5,\n",
    "}\n",
    "\n",
    "# A dict that maps the index to the class name (uses: decorate prediction)\n",
    "idx2class = {v:k for k,v in class2idx.items()}\n",
    "\n",
    "# A dict that maps the type given in the file name to our index(uses: dataset preparation)\n",
    "tag2idx = {\n",
    "    \"ANG\": 0,\n",
    "    \"DIS\": 1,\n",
    "    \"FEA\": 2,\n",
    "    \"HAP\": 3,\n",
    "    \"NEU\": 4,\n",
    "    \"SAD\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c9559f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:39:57.285571Z",
     "iopub.status.busy": "2024-09-19T03:39:57.284275Z",
     "iopub.status.idle": "2024-09-19T03:39:57.294996Z",
     "shell.execute_reply": "2024-09-19T03:39:57.293159Z"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1689170758206,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "kGYOIJQmgOic",
    "outputId": "66799748-dd45-40a9-ce3a-64ac90688e40",
    "papermill": {
     "duration": 0.058071,
     "end_time": "2024-09-19T03:39:57.298405",
     "exception": false,
     "start_time": "2024-09-19T03:39:57.240334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "idx2class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd002ec",
   "metadata": {
    "id": "IB2lBwgDmL4b",
    "papermill": {
     "duration": 0.037512,
     "end_time": "2024-09-19T03:39:57.374873",
     "exception": false,
     "start_time": "2024-09-19T03:39:57.337361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Defining the Transforms(Augmentation Techniques) and helper functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd61a05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:39:57.455283Z",
     "iopub.status.busy": "2024-09-19T03:39:57.454225Z",
     "iopub.status.idle": "2024-09-19T03:39:57.464463Z",
     "shell.execute_reply": "2024-09-19T03:39:57.462822Z"
    },
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1689170758208,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "xeTNYXx0lyTk",
    "papermill": {
     "duration": 0.054192,
     "end_time": "2024-09-19T03:39:57.467739",
     "exception": false,
     "start_time": "2024-09-19T03:39:57.413547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Defining the transforms:\n",
    "video_frame_transform = Compose([\n",
    "#     ToPILImage(),\n",
    "    Resize((252,252)),\n",
    "    CenterCrop((184,184)),\n",
    "#     ToTensor()\n",
    "])\n",
    "\n",
    "# change frame color randomly\n",
    "video_frame_augment_color = Compose([\n",
    "#     ToPILImage(),\n",
    "    Resize((252,252)),\n",
    "    CenterCrop((184,184)),\n",
    "    ColorJitter(brightness=0.4, hue=0.3, saturation=0.4),\n",
    "#     ToTensor()\n",
    "])\n",
    "\n",
    "# change frame prespective randomly\n",
    "video_frame_augment_persp = Compose([\n",
    "#     ToPILImage(),\n",
    "    Resize((252,252)),\n",
    "    CenterCrop((184,184)),\n",
    "    RandomPerspective(distortion_scale=0.3, p=1.0),\n",
    "#     ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad16d89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:39:57.547355Z",
     "iopub.status.busy": "2024-09-19T03:39:57.546829Z",
     "iopub.status.idle": "2024-09-19T03:39:57.565398Z",
     "shell.execute_reply": "2024-09-19T03:39:57.563659Z"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1689170758209,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "CHtHz0A7mgs6",
    "papermill": {
     "duration": 0.06305,
     "end_time": "2024-09-19T03:39:57.569548",
     "exception": false,
     "start_time": "2024-09-19T03:39:57.506498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Defining the helper functions for the Audio mel-spectogram technique\n",
    "\"\"\"\n",
    "\n",
    "# Get the melspec of the audio as image/np 2d array\n",
    "def wav2melSpec(AUDIO_PATH):\n",
    "    audio, sr = librosa.load(AUDIO_PATH)\n",
    "    return librosa.feature.melspectrogram(y=audio, sr=sr)\n",
    "\n",
    "\n",
    "# Show the image spectogram\n",
    "def imgSpec(ms_feature):\n",
    "    fig, ax = plt.subplots()\n",
    "    ms_dB = librosa.power_to_db(ms_feature, ref=np.max)\n",
    "    print(ms_feature.shape)\n",
    "    img = librosa.display.specshow(ms_dB, x_axis='time', y_axis='mel', ax=ax)\n",
    "    fig.colorbar(img, ax=ax, format='%+2.0f dB')\n",
    "    ax.set(title='Mel-frequency spectrogram');\n",
    "\n",
    "# Hear the audio\n",
    "def hear_audio(AUDIO_PATH):\n",
    "    audio, sr = librosa.load(AUDIO_PATH)\n",
    "\n",
    "    print(\"\\t\", end=\"\")\n",
    "    ipd.display(ipd.Audio(data=audio, rate=sr))\n",
    "\n",
    "\n",
    "def show_video(video_path):\n",
    "    from base64 import b64encode\n",
    "\n",
    "    if os.path.isfile(video_path):\n",
    "        ext = '.mp4'\n",
    "    else:\n",
    "        print(\"Error: Please check the path.\")\n",
    "\n",
    "    video_encoded = open(video_path, \"rb\").read()\n",
    "    data = \"data:video/mp4;base64,\" + b64encode(video_encoded).decode()\n",
    "\n",
    "    video_tag = '<video width=\"400\" height=\"300\" controls alt=\"test\" src=\"%s\">' % data\n",
    "    return HTML(data=video_tag)\n",
    "\n",
    "# Show 1 example\n",
    "def show_example(video_path, audio_path, prediction=None, actual=None, save_memory=False):\n",
    "    if prediction is not None:\n",
    "        print(\"Predicted Label:\", idx2class[prediction])\n",
    "    print(\"Actual Label:\", idx2class[actual])\n",
    "\n",
    "    if save_memory is False:\n",
    "        print(\"Video path:\", video_path)\n",
    "        ipd.display(Video(video_path, embed=True, width=400, height=300))\n",
    "\n",
    "        # display(show_video(video_path))\n",
    "        print(\"Audio path:\", audio_path)\n",
    "        hear_audio(audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c51a6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:39:57.652447Z",
     "iopub.status.busy": "2024-09-19T03:39:57.651911Z",
     "iopub.status.idle": "2024-09-19T03:39:57.941130Z",
     "shell.execute_reply": "2024-09-19T03:39:57.939680Z"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1689170758210,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "-SHmBEpnbl5y",
    "papermill": {
     "duration": 0.334672,
     "end_time": "2024-09-19T03:39:57.944605",
     "exception": false,
     "start_time": "2024-09-19T03:39:57.609933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Defining the helper functions for the Audio MFCC technique\n",
    "\"\"\"\n",
    "\n",
    "# audio effects\n",
    "def audio_effects(audio, sample_rate, augment=1):\n",
    "    data = None\n",
    "    if augment == 1:\n",
    "        data = librosa.effects.percussive(y=audio)\n",
    "    elif augment == 2:\n",
    "        data = librosa.effects.pitch_shift(y=audio, sr=sample_rate, n_steps=3)\n",
    "    return data\n",
    "\n",
    "\n",
    "# normalize the audio wave\n",
    "def normalize_audio(audio):\n",
    "    audio = audio / np.max(np.abs(audio))\n",
    "    return audio\n",
    "\n",
    "def feature_extractor(file, augment=0, test=False):\n",
    "\n",
    "    attempt = 0\n",
    "    while True:\n",
    "        try:\n",
    "            data, sample_rate = librosa.load(file)\n",
    "            break\n",
    "        except:\n",
    "            if attempt == 50:\n",
    "                print(\"failed trying to find audio file\", file)\n",
    "                break\n",
    "            print(\"Audio file not read. Trying again\")\n",
    "            attempt += 1\n",
    "\n",
    "#     print(data.shape)\n",
    "\n",
    "    if augment > 0:\n",
    "        data = audio_effects(data, sample_rate, augment=augment)\n",
    "\n",
    "    data = normalize_audio(data)\n",
    "\n",
    "    # zero crossing rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(y=data)[0]\n",
    "    zcr /= zcr.max()\n",
    "    zcr = zcr[0:(0+128)]\n",
    "    if len(zcr) < 128:\n",
    "        zcr = librosa.util.fix_length(zcr, size=128)\n",
    "#     result=np.vstack((result, zcr))\n",
    "\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=128).T, axis=0)\n",
    "    mfcc /= mfcc.max()\n",
    "#     result = np.vstack((result, mfcc))\n",
    "\n",
    "    # Root Mean Square Value\n",
    "    rms = librosa.feature.rms(y=data)[0]\n",
    "    rms /= rms.max()\n",
    "    rms = rms[0:(0+128)]\n",
    "    if len(rms) < 128:\n",
    "        rms = librosa.util.fix_length(rms, size=128)\n",
    "#     result = np.vstack((result, rms))\n",
    "\n",
    "    # MelSpectogram\n",
    "    mel = librosa.feature.melspectrogram(y=data, sr=sample_rate)\n",
    "    mel = librosa.amplitude_to_db(mel, ref = np.max)\n",
    "    mel = np.mean(mel.T, axis=0)\n",
    "    mel /= mel.sum()\n",
    "#     result = np.vstack((result, mel))\n",
    "\n",
    "    if test:\n",
    "        return_dict = {\n",
    "            \"raw\": data,\n",
    "            \"sr\": sample_rate,\n",
    "            \"zcr\": zcr,\n",
    "            \"mfcc\": mfcc,\n",
    "            \"rms\": rms,\n",
    "            \"mel\": mel\n",
    "        }\n",
    "    else:\n",
    "        return_dict = {\n",
    "            \"zcr\": zcr,\n",
    "            \"mfcc\": mfcc,\n",
    "            \"rms\": rms,\n",
    "            \"mel\": mel\n",
    "        }\n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9583e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:39:58.027608Z",
     "iopub.status.busy": "2024-09-19T03:39:58.026856Z",
     "iopub.status.idle": "2024-09-19T03:39:58.035289Z",
     "shell.execute_reply": "2024-09-19T03:39:58.033943Z"
    },
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1689170758212,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "F2iAzdWbbl5z",
    "papermill": {
     "duration": 0.053481,
     "end_time": "2024-09-19T03:39:58.038056",
     "exception": false,
     "start_time": "2024-09-19T03:39:57.984575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dict_to_tensor(dictionary):\n",
    "    out_dict = {}\n",
    "    for item in dictionary.items():\n",
    "        if item[0] == \"sr\":\n",
    "            out_dict[item[0]] = torch.tensor(item[1]).to(device)\n",
    "        else:\n",
    "            out_dict[item[0]] = torch.from_numpy(item[1]).to(device)\n",
    "\n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0998118",
   "metadata": {
    "id": "x3rsMw5Wj58W",
    "papermill": {
     "duration": 0.039677,
     "end_time": "2024-09-19T03:39:58.117663",
     "exception": false,
     "start_time": "2024-09-19T03:39:58.077986",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "<br/>\n",
    "\n",
    "## **Dataset Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73535a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:39:58.203510Z",
     "iopub.status.busy": "2024-09-19T03:39:58.202940Z",
     "iopub.status.idle": "2024-09-19T03:39:58.218781Z",
     "shell.execute_reply": "2024-09-19T03:39:58.217181Z"
    },
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1689170758213,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "ae0Y6LRzi4AI",
    "papermill": {
     "duration": 0.064622,
     "end_time": "2024-09-19T03:39:58.222362",
     "exception": false,
     "start_time": "2024-09-19T03:39:58.157740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a tuple of audio, video, labels\n",
    "def make_ds_as_list(path):\n",
    "    audio = []\n",
    "    video = []\n",
    "    labels = []\n",
    "    for dirname, _, filenames in sorted(os.walk(f\"{path}VideoFlash\")):\n",
    "        for filename in sorted(filenames):\n",
    "            \n",
    "            if filename in [\"script.py\", \"1076_MTI_NEU_XX.mp4\", \"1076_MTI_SAD_XX.mp4\", \"1064_TIE_SAD_XX.mp4\", \"1064_IEO_DIS_MD.mp4\"]:\n",
    "                continue\n",
    "            \n",
    "            video_path = os.path.join(dirname, filename)\n",
    "            label = filename.split('_')[2]\n",
    "            label = tag2idx[label]\n",
    "            video.append(video_path)\n",
    "            labels.append(label)\n",
    "\n",
    "\n",
    "    for dirname, _, filenames in sorted(os.walk(f\"{path}AudioWAV\")):\n",
    "        for filename in sorted(filenames):\n",
    "            \n",
    "            if filename in [\"script.py\", \"1076_MTI_NEU_XX.wav\", \"1076_MTI_SAD_XX.wav\", \"1064_TIE_SAD_XX.wav\", \"1064_IEO_DIS_MD.wav\"]:\n",
    "                continue\n",
    "            \n",
    "            audio_path = os.path.join(dirname, filename)\n",
    "            audio.append(audio_path)\n",
    "\n",
    "    return audio, video, labels\n",
    "\n",
    "# Create a dataframe\n",
    "def make_dataframe(path, augment=0):\n",
    "    audio, video, labels = make_ds_as_list(path)\n",
    "    data = pd.DataFrame()\n",
    "    data['audio_path'] = audio\n",
    "    data['video_path'] = video\n",
    "    data['label'] = labels\n",
    "    data['augment'] = augment\n",
    "\n",
    "    del audio\n",
    "    del video\n",
    "    del labels\n",
    "    gc.collect()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7735f96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:39:58.310473Z",
     "iopub.status.busy": "2024-09-19T03:39:58.309875Z",
     "iopub.status.idle": "2024-09-19T03:40:04.716750Z",
     "shell.execute_reply": "2024-09-19T03:40:04.715436Z"
    },
    "executionInfo": {
     "elapsed": 9793,
     "status": "ok",
     "timestamp": 1689170767968,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "46gw50AkjxaM",
    "papermill": {
     "duration": 6.454711,
     "end_time": "2024-09-19T03:40:04.720291",
     "exception": false,
     "start_time": "2024-09-19T03:39:58.265580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make the dataset\n",
    "non_augment_df = make_dataframe(working_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8e6a47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:04.807019Z",
     "iopub.status.busy": "2024-09-19T03:40:04.806580Z",
     "iopub.status.idle": "2024-09-19T03:40:04.824843Z",
     "shell.execute_reply": "2024-09-19T03:40:04.823603Z"
    },
    "executionInfo": {
     "elapsed": 86,
     "status": "ok",
     "timestamp": 1689170767971,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "qznheMRZpwn_",
    "outputId": "fa14c15e-413b-41f1-aeea-6bb378b94d92",
    "papermill": {
     "duration": 0.064551,
     "end_time": "2024-09-19T03:40:04.828064",
     "exception": false,
     "start_time": "2024-09-19T03:40:04.763513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "augment_1_df = non_augment_df.copy()\n",
    "augment_1_df[\"augment\"] = 1\n",
    "\n",
    "augment_2_df = non_augment_df.copy()\n",
    "augment_2_df[\"augment\"] = 2\n",
    "\n",
    "non_augment_df[\"augment\"] = 0\n",
    "\n",
    "# check an example to see if the strings/naming conventions match\n",
    "non_augment_df[\"audio_path\"][0], non_augment_df[\"video_path\"][0], augment_1_df[\"audio_path\"][0], augment_1_df[\"video_path\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d8e265",
   "metadata": {
    "id": "HR6vvmZTbl52",
    "papermill": {
     "duration": 0.039611,
     "end_time": "2024-09-19T03:40:04.908236",
     "exception": false,
     "start_time": "2024-09-19T03:40:04.868625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br>\n",
    "<hr>\n",
    "\n",
    "## Data checking and testing phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc628e5a",
   "metadata": {
    "id": "vaT-_1Qobl52",
    "papermill": {
     "duration": 0.040153,
     "end_time": "2024-09-19T03:40:04.991124",
     "exception": false,
     "start_time": "2024-09-19T03:40:04.950971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Do the transforms work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc47c199",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:05.072820Z",
     "iopub.status.busy": "2024-09-19T03:40:05.072387Z",
     "iopub.status.idle": "2024-09-19T03:40:05.079823Z",
     "shell.execute_reply": "2024-09-19T03:40:05.078252Z"
    },
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1689170767973,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "xnC2SUc3bl53",
    "papermill": {
     "duration": 0.051751,
     "end_time": "2024-09-19T03:40:05.082863",
     "exception": false,
     "start_time": "2024-09-19T03:40:05.031112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# idx = 50\n",
    "\n",
    "\n",
    "# # RAW AUDIO\n",
    "# d = feature_extractor(non_augment_df[\"audio_path\"][idx], augment=0, test=True)\n",
    "# data = d[\"raw\"]\n",
    "# sr = d[\"sr\"]\n",
    "# print(\"Audio transformed with augmentation scheme 0 (no augementation; raw audio):\")\n",
    "# ipd.display(ipd.Audio(data=data, rate=sr))\n",
    "# print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # AUGMENTATION 1 - harmonic\n",
    "# d = feature_extractor(augment_1_df[\"audio_path\"][idx], augment=1, test=True)\n",
    "# data = d[\"raw\"]\n",
    "# sr = d[\"sr\"]\n",
    "# print(\"Audio transformed with augmentation scheme 1:\")\n",
    "# ipd.display(ipd.Audio(data=data, rate=sr))\n",
    "# print(\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# # AUGMENTATION 2 - pitch shift\n",
    "# d = feature_extractor(augment_2_df[\"audio_path\"][idx], augment=2, test=True)\n",
    "# data = d[\"raw\"]\n",
    "# sr = d[\"sr\"]\n",
    "# print(\"Audio transformed with augmentation scheme 2:\")\n",
    "# ipd.display(ipd.Audio(data=data, rate=sr))\n",
    "# print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a9c7b3",
   "metadata": {
    "papermill": {
     "duration": 0.040612,
     "end_time": "2024-09-19T03:40:05.163675",
     "exception": false,
     "start_time": "2024-09-19T03:40:05.123063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9f82b1d",
   "metadata": {
    "id": "GXJuI6cJbl53",
    "papermill": {
     "duration": 0.041977,
     "end_time": "2024-09-19T03:40:05.247053",
     "exception": false,
     "start_time": "2024-09-19T03:40:05.205076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**YES THEY DO!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0182dbe8",
   "metadata": {
    "id": "ftc1ACEQbl54",
    "papermill": {
     "duration": 0.042828,
     "end_time": "2024-09-19T03:40:05.330977",
     "exception": false,
     "start_time": "2024-09-19T03:40:05.288149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br>\n",
    "<hr>\n",
    "\n",
    "#### Checking the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03116858",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:05.419005Z",
     "iopub.status.busy": "2024-09-19T03:40:05.417905Z",
     "iopub.status.idle": "2024-09-19T03:40:05.438484Z",
     "shell.execute_reply": "2024-09-19T03:40:05.436333Z"
    },
    "executionInfo": {
     "elapsed": 77,
     "status": "ok",
     "timestamp": 1689170767975,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "IanxxfASbl54",
    "outputId": "c0c7dd92-a3bc-48b2-dc0e-143837fd3333",
    "papermill": {
     "duration": 0.06951,
     "end_time": "2024-09-19T03:40:05.442843",
     "exception": false,
     "start_time": "2024-09-19T03:40:05.373333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "augment_1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637d8014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:05.551440Z",
     "iopub.status.busy": "2024-09-19T03:40:05.549916Z",
     "iopub.status.idle": "2024-09-19T03:40:05.565529Z",
     "shell.execute_reply": "2024-09-19T03:40:05.564237Z"
    },
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1689170767977,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "nbIKJrMxbl55",
    "outputId": "f8bdcebb-65b3-476c-a923-6eaf8d194920",
    "papermill": {
     "duration": 0.067328,
     "end_time": "2024-09-19T03:40:05.568596",
     "exception": false,
     "start_time": "2024-09-19T03:40:05.501268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "augment_2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2f5c65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:05.659306Z",
     "iopub.status.busy": "2024-09-19T03:40:05.657424Z",
     "iopub.status.idle": "2024-09-19T03:40:05.690698Z",
     "shell.execute_reply": "2024-09-19T03:40:05.689447Z"
    },
    "executionInfo": {
     "elapsed": 73,
     "status": "ok",
     "timestamp": 1689170767979,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "kqQDeVdPbl55",
    "outputId": "f0d25313-026b-406f-819d-c5f14c3dd8da",
    "papermill": {
     "duration": 0.083036,
     "end_time": "2024-09-19T03:40:05.695304",
     "exception": false,
     "start_time": "2024-09-19T03:40:05.612268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "non_augment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05857bef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:05.807014Z",
     "iopub.status.busy": "2024-09-19T03:40:05.806580Z",
     "iopub.status.idle": "2024-09-19T03:40:05.824610Z",
     "shell.execute_reply": "2024-09-19T03:40:05.823119Z"
    },
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1689170767981,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "tFMkKXKybl56",
    "outputId": "59b43b99-f32f-43d7-fa49-fd4c5564625d",
    "papermill": {
     "duration": 0.073072,
     "end_time": "2024-09-19T03:40:05.827781",
     "exception": false,
     "start_time": "2024-09-19T03:40:05.754709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.concat([non_augment_df, augment_1_df, augment_2_df])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb1b954",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:05.912480Z",
     "iopub.status.busy": "2024-09-19T03:40:05.912042Z",
     "iopub.status.idle": "2024-09-19T03:40:05.922686Z",
     "shell.execute_reply": "2024-09-19T03:40:05.921223Z"
    },
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1689170767984,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "icbcM0G6bl56",
    "outputId": "444dc95f-009f-4c97-dddb-030ac7eb153d",
    "papermill": {
     "duration": 0.056253,
     "end_time": "2024-09-19T03:40:05.925759",
     "exception": false,
     "start_time": "2024-09-19T03:40:05.869506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(non_augment_df), len(augment_1_df), len(augment_2_df), len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c5c5db",
   "metadata": {
    "id": "Y8lyicr7nx6K",
    "papermill": {
     "duration": 0.040284,
     "end_time": "2024-09-19T03:40:06.007384",
     "exception": false,
     "start_time": "2024-09-19T03:40:05.967100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br/>\n",
    "\n",
    "---\n",
    "\n",
    "## **Dataset Splitting**\n",
    "\n",
    "We will now split the dataset into train, cv, test splits.\n",
    "\n",
    "60:20:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b6bbc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:06.091651Z",
     "iopub.status.busy": "2024-09-19T03:40:06.091072Z",
     "iopub.status.idle": "2024-09-19T03:40:06.116828Z",
     "shell.execute_reply": "2024-09-19T03:40:06.115258Z"
    },
    "executionInfo": {
     "elapsed": 65,
     "status": "ok",
     "timestamp": 1689170767987,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "4WVZ1JCxlNTC",
    "outputId": "0ad109ee-d853-4f09-ed97-b17206cc4b61",
    "papermill": {
     "duration": 0.072158,
     "end_time": "2024-09-19T03:40:06.120146",
     "exception": false,
     "start_time": "2024-09-19T03:40:06.047988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split into 60% train, 20% val, 20% test set\n",
    "train_df, test_df = train_test_split(df, test_size=0.40, random_state=42)\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a6540d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:06.204646Z",
     "iopub.status.busy": "2024-09-19T03:40:06.204057Z",
     "iopub.status.idle": "2024-09-19T03:40:06.210746Z",
     "shell.execute_reply": "2024-09-19T03:40:06.209253Z"
    },
    "executionInfo": {
     "elapsed": 24227,
     "status": "ok",
     "timestamp": 1689170792155,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "fU2NCTHRlWX6",
    "outputId": "835a3e0b-2bc1-48ab-daf6-0d8d25b6aa68",
    "papermill": {
     "duration": 0.051849,
     "end_time": "2024-09-19T03:40:06.213588",
     "exception": false,
     "start_time": "2024-09-19T03:40:06.161739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Check your examples\n",
    "# idx = 90 # Change index to see different examples\n",
    "# show_example(train_df[\"video_path\"].iloc[idx], train_df[\"audio_path\"].iloc[idx], actual=train_df[\"label\"].iloc[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca10c9a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:06.299918Z",
     "iopub.status.busy": "2024-09-19T03:40:06.299456Z",
     "iopub.status.idle": "2024-09-19T03:40:06.311807Z",
     "shell.execute_reply": "2024-09-19T03:40:06.310611Z"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1689170792156,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "BiN_jVU4oHE_",
    "papermill": {
     "duration": 0.060183,
     "end_time": "2024-09-19T03:40:06.314896",
     "exception": false,
     "start_time": "2024-09-19T03:40:06.254713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_df, test_df = train_test_split(test_df, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c836c09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:06.400253Z",
     "iopub.status.busy": "2024-09-19T03:40:06.399814Z",
     "iopub.status.idle": "2024-09-19T03:40:06.408806Z",
     "shell.execute_reply": "2024-09-19T03:40:06.407325Z"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1689170792157,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "eiF5Ib33oxsr",
    "outputId": "002c7f27-816a-4fd0-f8e4-92a2a0666812",
    "papermill": {
     "duration": 0.054561,
     "end_time": "2024-09-19T03:40:06.411616",
     "exception": false,
     "start_time": "2024-09-19T03:40:06.357055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# View their length\n",
    "len(train_df), len(cv_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840505ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:06.495756Z",
     "iopub.status.busy": "2024-09-19T03:40:06.495274Z",
     "iopub.status.idle": "2024-09-19T03:40:06.761184Z",
     "shell.execute_reply": "2024-09-19T03:40:06.760000Z"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1689170792158,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "eXyeRaD2ucNK",
    "outputId": "72194217-0552-426c-e46b-1765890223c2",
    "papermill": {
     "duration": 0.311182,
     "end_time": "2024-09-19T03:40:06.764052",
     "exception": false,
     "start_time": "2024-09-19T03:40:06.452870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del df, non_augment_df, augment_1_df, augment_2_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf0067f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:06.849497Z",
     "iopub.status.busy": "2024-09-19T03:40:06.849026Z",
     "iopub.status.idle": "2024-09-19T03:40:06.854749Z",
     "shell.execute_reply": "2024-09-19T03:40:06.853530Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1689170792158,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "V1Eq348OqFIc",
    "papermill": {
     "duration": 0.051688,
     "end_time": "2024-09-19T03:40:06.857656",
     "exception": false,
     "start_time": "2024-09-19T03:40:06.805968",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65214e54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:06.942077Z",
     "iopub.status.busy": "2024-09-19T03:40:06.941401Z",
     "iopub.status.idle": "2024-09-19T03:40:06.948528Z",
     "shell.execute_reply": "2024-09-19T03:40:06.946273Z"
    },
    "papermill": {
     "duration": 0.053297,
     "end_time": "2024-09-19T03:40:06.951782",
     "exception": false,
     "start_time": "2024-09-19T03:40:06.898485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# videodata = skvideo.io.vread(\"/kaggle/input/cremad/CREMA-D/VideoFlash/1066_IOM_DIS_XX.mp4\")  \n",
    "# print(videodata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ea3fc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:07.033728Z",
     "iopub.status.busy": "2024-09-19T03:40:07.033265Z",
     "iopub.status.idle": "2024-09-19T03:40:07.039228Z",
     "shell.execute_reply": "2024-09-19T03:40:07.037821Z"
    },
    "papermill": {
     "duration": 0.050409,
     "end_time": "2024-09-19T03:40:07.042263",
     "exception": false,
     "start_time": "2024-09-19T03:40:06.991854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# videodata = torch.Tensor(videodata)\n",
    "# videodata /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070a205",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:07.148151Z",
     "iopub.status.busy": "2024-09-19T03:40:07.147626Z",
     "iopub.status.idle": "2024-09-19T03:40:07.154790Z",
     "shell.execute_reply": "2024-09-19T03:40:07.153149Z"
    },
    "papermill": {
     "duration": 0.073012,
     "end_time": "2024-09-19T03:40:07.158139",
     "exception": false,
     "start_time": "2024-09-19T03:40:07.085127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i, frame in enumerate(videodata):\n",
    "#     frame = frame.numpy()\n",
    "#     plt.imshow(frame)\n",
    "#     plt.show()\n",
    "    \n",
    "#     if i == 10:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2aff5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:07.255573Z",
     "iopub.status.busy": "2024-09-19T03:40:07.255052Z",
     "iopub.status.idle": "2024-09-19T03:40:07.287692Z",
     "shell.execute_reply": "2024-09-19T03:40:07.286464Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1689170792159,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "TtHooQt9jzUo",
    "papermill": {
     "duration": 0.088439,
     "end_time": "2024-09-19T03:40:07.291758",
     "exception": false,
     "start_time": "2024-09-19T03:40:07.203319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# The dataset to use in the dataloader\n",
    "class CREMADataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        dataframe, \n",
    "        video_frame_transform=None, \n",
    "        video_strategy='optimal', \n",
    "        cut_video=False, \n",
    "        cut_audio=False, \n",
    "        selection=\"quartile\", \n",
    "        variant=\"all\"\n",
    "    ):\n",
    "\n",
    "        self.cut_video = cut_video\n",
    "        self.cut_audio = cut_audio\n",
    "\n",
    "        self.examples = dataframe\n",
    "        self.video_frame_transform = {\n",
    "            0: video_frame_transform,\n",
    "            1: video_frame_augment_color,\n",
    "            2: video_frame_augment_persp\n",
    "        }\n",
    "    \n",
    "        self.video_strategy = video_strategy\n",
    "        self.selection = selection\n",
    "        self.variant = variant\n",
    "\n",
    "        del dataframe, video_frame_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "\n",
    "    def __optimal_strategy(self, video, augment=0):\n",
    "\n",
    "        frames = []\n",
    "\n",
    "        q1_point = video.shape[0] // 4\n",
    "        q2_point = video.shape[0] // 2\n",
    "        q3_point = int((video.shape[0] * (3/4)))\n",
    "        length = video.shape[0]\n",
    "\n",
    "        q1_q2_mid = int((q1_point + (q2_point - 5))//2)\n",
    "        q2_q3_mid = int((q2_point + (q3_point - 5))//2)\n",
    "\n",
    "        q1_lb = q1_point-10\n",
    "        q1_up = q1_q2_mid\n",
    "\n",
    "        q2_lb = q2_point-10\n",
    "        q2_up = q2_q3_mid\n",
    "\n",
    "        q3_lb = q3_point-10\n",
    "        \n",
    "        six_frame_lower_bound = (self.selection == \"six\" and self.variant == \"lower\")\n",
    "        six_frame_upper_bound = (self.selection == \"six\" and self.variant == \"upper\")\n",
    "        original_strategy = (self.selection == \"quartile\" and self.variant == \"all\")\n",
    "        \n",
    "        # select random starting frames\n",
    "        if six_frame_lower_bound or original_strategy:\n",
    "            frames.append(self.video_frame_transform[augment](video[q1_lb]))\n",
    "        frames.append(self.video_frame_transform[augment](video[q1_point]))\n",
    "        if six_frame_upper_bound or original_strategy:\n",
    "            frames.append(self.video_frame_transform[augment](video[q1_up]))\n",
    "            \n",
    "        # select random mid frames\n",
    "        if six_frame_lower_bound or original_strategy:\n",
    "            frames.append(self.video_frame_transform[augment](video[q2_lb]))\n",
    "        frames.append(self.video_frame_transform[augment](video[q2_point]))\n",
    "        if six_frame_upper_bound or original_strategy:\n",
    "            frames.append(self.video_frame_transform[augment](video[q2_up]))\n",
    "\n",
    "        # select random end frames\n",
    "        if six_frame_lower_bound or original_strategy:\n",
    "            frames.append(self.video_frame_transform[augment](video[q3_lb]))\n",
    "        frames.append(self.video_frame_transform[augment](video[q3_point]))\n",
    "        if six_frame_upper_bound or original_strategy:\n",
    "            frames.append(self.video_frame_transform[augment](video[-1]))\n",
    "\n",
    "        frames = torch.stack(frames)\n",
    "\n",
    "        return frames\n",
    "\n",
    "\n",
    "    def __all_strategy(self, video):\n",
    "        length = video.shape[0]\n",
    "\n",
    "        frames = []\n",
    "        for i, f in enumerate(video):\n",
    "            if i == hyperparams[\"max_seq_len\"]:\n",
    "                break\n",
    "            frame = self.video_frame_transform(f)\n",
    "            frames.append(frame)\n",
    "            del frame\n",
    "            gc.collect()\n",
    "\n",
    "\n",
    "        if length < hyperparams[\"max_seq_len\"]:\n",
    "            diff = hyperparams[\"max_seq_len\"] - length\n",
    "\n",
    "            Q2 = int(length // 2)\n",
    "            for i in range(Q2, Q2 + diff):\n",
    "                frames.append(self.video_frame_transform(video[i]))\n",
    "\n",
    "        frames = torch.stack(frames)\n",
    "        del video\n",
    "        gc.collect()\n",
    "\n",
    "        return frames\n",
    "\n",
    "\n",
    "    def __audio_extraction(self, audio, augment=0):\n",
    "        feats = feature_extractor(audio, augment)\n",
    "        return dict_to_tensor(feats)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        df = self.examples.iloc[idx]\n",
    "        audio_path, video_path, label, augment = df[\"audio_path\"], df[\"video_path\"], df[\"label\"], df['augment']\n",
    "\n",
    "        if self.cut_video == False:\n",
    "\n",
    "            attempt = 0\n",
    "            while True:\n",
    "                try:\n",
    "                    video = skvideo.io.vread(video_path)\n",
    "                    video = torch.Tensor(video)\n",
    "                    video /= 255.0\n",
    "                    break\n",
    "                except:\n",
    "                    if attempt == 50:\n",
    "                        print(\"Video file can't be read\", video_path)\n",
    "                        break\n",
    "                    print(\"Video file not read. Trying again\")\n",
    "                    attempt += 1\n",
    "\n",
    "\n",
    "            video = torch.permute(video, (0,3,1,2))\n",
    "\n",
    "            if self.video_strategy == 'optimal':\n",
    "                video = self.__optimal_strategy(video, augment)\n",
    "            elif self.video_strategy == 'all':\n",
    "                video = self.__all_strategy(video)\n",
    "        else:\n",
    "            video = torch.zeros((1,1))\n",
    "\n",
    "        if self.cut_audio == False:\n",
    "            audio = self.__audio_extraction(audio_path, augment)\n",
    "        else:\n",
    "            audio = torch.zeros((1,1))\n",
    "\n",
    "\n",
    "        del df\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "        return video, audio, label, video_path, audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a687d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:07.408457Z",
     "iopub.status.busy": "2024-09-19T03:40:07.407910Z",
     "iopub.status.idle": "2024-09-19T03:40:07.417720Z",
     "shell.execute_reply": "2024-09-19T03:40:07.416447Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1689170792160,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "_PD7KdpAjzR0",
    "papermill": {
     "duration": 0.062558,
     "end_time": "2024-09-19T03:40:07.421590",
     "exception": false,
     "start_time": "2024-09-19T03:40:07.359032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainds = CREMADataset(train_df, video_frame_transform)\n",
    "cvds = CREMADataset(cv_df, video_frame_transform)\n",
    "testds = CREMADataset(test_df, video_frame_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e7e955",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:07.517582Z",
     "iopub.status.busy": "2024-09-19T03:40:07.516420Z",
     "iopub.status.idle": "2024-09-19T03:40:07.525162Z",
     "shell.execute_reply": "2024-09-19T03:40:07.523647Z"
    },
    "executionInfo": {
     "elapsed": 1229,
     "status": "ok",
     "timestamp": 1689170793378,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "O34tXEQvjzO3",
    "papermill": {
     "duration": 0.059966,
     "end_time": "2024-09-19T03:40:07.528395",
     "exception": false,
     "start_time": "2024-09-19T03:40:07.468429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainds, batch_size=hyperparams[\"batch\"], shuffle=True)\n",
    "cvloader = DataLoader(cvds, batch_size=hyperparams[\"batch\"], shuffle=False)\n",
    "testloader = DataLoader(testds, batch_size=hyperparams[\"batch\"], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33decd2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:07.624910Z",
     "iopub.status.busy": "2024-09-19T03:40:07.624124Z",
     "iopub.status.idle": "2024-09-19T03:40:07.920808Z",
     "shell.execute_reply": "2024-09-19T03:40:07.919251Z"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1689170793379,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "tO-T4pmUbl5_",
    "outputId": "90c2579b-f69d-4f15-db6c-c34943ec4d36",
    "papermill": {
     "duration": 0.351108,
     "end_time": "2024-09-19T03:40:07.924433",
     "exception": false,
     "start_time": "2024-09-19T03:40:07.573325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del trainds\n",
    "del cvds\n",
    "del testds\n",
    "del train_df\n",
    "del cv_df\n",
    "del test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea1e567",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:08.020316Z",
     "iopub.status.busy": "2024-09-19T03:40:08.019798Z",
     "iopub.status.idle": "2024-09-19T03:40:08.030004Z",
     "shell.execute_reply": "2024-09-19T03:40:08.028300Z"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1689170793379,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "Omwz_LK5bl6R",
    "papermill": {
     "duration": 0.061125,
     "end_time": "2024-09-19T03:40:08.033128",
     "exception": false,
     "start_time": "2024-09-19T03:40:07.972003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def view_a_loader(item, i):\n",
    "    video, audio, label, video_p, audio_p = item\n",
    "    show_example(video_p[i], audio_p[i], label[i].item(), label[i].item())\n",
    "    print(f\"Video shape: {video.shape} | Audio shape: {audio['mel'].shape}\")\n",
    "    print(f\"{video_p[i]}\")\n",
    "    for f in video[i]:\n",
    "        print(f[0])\n",
    "        f = torch.permute(f, (1,2,0))\n",
    "        plt.figure(figsize=(3, 3))\n",
    "        plt.imshow(f.numpy())\n",
    "        plt.show()\n",
    "#     imgSpec(audio[i].squeeze())\n",
    "\n",
    "    del item, video, audio, label, video_p, audio_p\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a49a16e",
   "metadata": {
    "id": "h3WEdO8OrGE7",
    "papermill": {
     "duration": 0.040658,
     "end_time": "2024-09-19T03:40:08.406602",
     "exception": false,
     "start_time": "2024-09-19T03:40:08.365944",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **The Model**\n",
    "\n",
    "It's time to build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdeedf2",
   "metadata": {
    "id": "1A1UqmQcbl6T",
    "papermill": {
     "duration": 0.040863,
     "end_time": "2024-09-19T03:40:08.488618",
     "exception": false,
     "start_time": "2024-09-19T03:40:08.447755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### The Video Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ad65ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:08.572531Z",
     "iopub.status.busy": "2024-09-19T03:40:08.571905Z",
     "iopub.status.idle": "2024-09-19T03:40:10.320953Z",
     "shell.execute_reply": "2024-09-19T03:40:10.319471Z"
    },
    "executionInfo": {
     "elapsed": 8654,
     "status": "ok",
     "timestamp": 1689170802021,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "D3AfeLqtbl6U",
    "outputId": "4b36ca1b-0062-4129-f540-a258a1431518",
    "papermill": {
     "duration": 1.795643,
     "end_time": "2024-09-19T03:40:10.324822",
     "exception": false,
     "start_time": "2024-09-19T03:40:08.529179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models.video import r2plus1d_18\n",
    "\n",
    "R2plus1D = r2plus1d_18(weights='KINETICS400_V1').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e0b46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:10.425160Z",
     "iopub.status.busy": "2024-09-19T03:40:10.424710Z",
     "iopub.status.idle": "2024-09-19T03:40:10.439419Z",
     "shell.execute_reply": "2024-09-19T03:40:10.437579Z"
    },
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1689170802022,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "W31ILVnDbl6U",
    "outputId": "729f015b-1751-45a2-9142-2415d7d2cf8a",
    "papermill": {
     "duration": 0.071849,
     "end_time": "2024-09-19T03:40:10.443391",
     "exception": false,
     "start_time": "2024-09-19T03:40:10.371542",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "R2plus1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3364398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:10.540594Z",
     "iopub.status.busy": "2024-09-19T03:40:10.540014Z",
     "iopub.status.idle": "2024-09-19T03:40:10.546989Z",
     "shell.execute_reply": "2024-09-19T03:40:10.545430Z"
    },
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1689170802023,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "CTAtuAoUbl6V",
    "papermill": {
     "duration": 0.060708,
     "end_time": "2024-09-19T03:40:10.550618",
     "exception": false,
     "start_time": "2024-09-19T03:40:10.489910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models.video.resnet import Conv2Plus1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258d5424",
   "metadata": {
    "id": "S4guMEY8bl6W",
    "papermill": {
     "duration": 0.041541,
     "end_time": "2024-09-19T03:40:10.636545",
     "exception": false,
     "start_time": "2024-09-19T03:40:10.595004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<hr>\n",
    "<br>\n",
    "\n",
    "\n",
    "### The Audio Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8b198a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:10.837073Z",
     "iopub.status.busy": "2024-09-19T03:40:10.836573Z",
     "iopub.status.idle": "2024-09-19T03:40:10.843884Z",
     "shell.execute_reply": "2024-09-19T03:40:10.842569Z"
    },
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1689170802024,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "sa8NMi1rbl6Y",
    "papermill": {
     "duration": 0.059097,
     "end_time": "2024-09-19T03:40:10.847079",
     "exception": false,
     "start_time": "2024-09-19T03:40:10.787982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PassThrough(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb7f55d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:11.069811Z",
     "iopub.status.busy": "2024-09-19T03:40:11.069369Z",
     "iopub.status.idle": "2024-09-19T03:40:11.085104Z",
     "shell.execute_reply": "2024-09-19T03:40:11.083432Z"
    },
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1689170802026,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "blyDHcAhbl6b",
    "papermill": {
     "duration": 0.070406,
     "end_time": "2024-09-19T03:40:11.088883",
     "exception": false,
     "start_time": "2024-09-19T03:40:11.018477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Conv1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 128, kernel_size=3, dilation=2, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv1d(128, 128, kernel_size=3, dilation=2, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.GroupNorm(1, 128)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, kernel_size=3, dilation=2, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv1d(128, 128, kernel_size=3, dilation=2, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.GroupNorm(1, 128)\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(128, 128, kernel_size=3, dilation=2, bias=False),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.GroupNorm(1, 128)\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = self.conv3(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a514a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:11.183138Z",
     "iopub.status.busy": "2024-09-19T03:40:11.182715Z",
     "iopub.status.idle": "2024-09-19T03:40:11.192730Z",
     "shell.execute_reply": "2024-09-19T03:40:11.191212Z"
    },
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1689170802026,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "RqO8d9FqZegd",
    "papermill": {
     "duration": 0.059481,
     "end_time": "2024-09-19T03:40:11.195707",
     "exception": false,
     "start_time": "2024-09-19T03:40:11.136226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SENet(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "\n",
    "        self.se_net = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(channels // reduction, channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.global_pooling_bridge = nn.AdaptiveAvgPool1d(1)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.global_pooling_bridge(x)\n",
    "#         print(\"shape input to se net: \", out.shape)\n",
    "        out = self.flatten(out)\n",
    "        out = self.se_net(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab70e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:11.284576Z",
     "iopub.status.busy": "2024-09-19T03:40:11.283370Z",
     "iopub.status.idle": "2024-09-19T03:40:11.295009Z",
     "shell.execute_reply": "2024-09-19T03:40:11.293247Z"
    },
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1689170802027,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "vu5yeD7GZfPx",
    "papermill": {
     "duration": 0.059045,
     "end_time": "2024-09-19T03:40:11.297973",
     "exception": false,
     "start_time": "2024-09-19T03:40:11.238928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DaggerNetV2(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn_encoder = Conv1D()\n",
    "\n",
    "        self.se_net = SENet(channels=128)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.global_pooling = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.cnn_encoder(x)\n",
    "        residual = out\n",
    "\n",
    "#         print(\"CNN out: \", out.shape)\n",
    "\n",
    "        attn_out = self.se_net(out)\n",
    "\n",
    "#         print(\"SE net out: \", attn_out.shape)\n",
    "\n",
    "        attn_out = attn_out.unsqueeze(dim=-1)\n",
    "\n",
    "        out_total = attn_out * residual\n",
    "\n",
    "#         out_total = self.global_pooling(out_total)\n",
    "        out_total = self.flatten(out_total)\n",
    "\n",
    "#         print(\"Output: \", out_total.shape)\n",
    "\n",
    "        return out_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bef0b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:11.388771Z",
     "iopub.status.busy": "2024-09-19T03:40:11.388306Z",
     "iopub.status.idle": "2024-09-19T03:40:11.405557Z",
     "shell.execute_reply": "2024-09-19T03:40:11.403829Z"
    },
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1689170802027,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "lFi9e5M7bl6c",
    "papermill": {
     "duration": 0.067194,
     "end_time": "2024-09-19T03:40:11.409066",
     "exception": false,
     "start_time": "2024-09-19T03:40:11.341872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AudioFeatureExtractor(nn.Module):\n",
    "    def __init__(self, rnn_hidden_size, rnn_num_layers):\n",
    "        super().__init__()\n",
    "\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.rnn_num_layers = rnn_num_layers\n",
    "\n",
    "\n",
    "        self.zcr_net = DaggerNetV2()\n",
    "        self.rms_net = DaggerNetV2()\n",
    "        self.mfcc_net = DaggerNetV2()\n",
    "        self.mel_net = DaggerNetV2()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x[\"mfcc\"] = x[\"mfcc\"].unsqueeze(dim=1).float()\n",
    "        x[\"zcr\"] = x[\"zcr\"].unsqueeze(dim=1).float()\n",
    "        x[\"mel\"] = x[\"mel\"].unsqueeze(dim=1).float()\n",
    "        x[\"rms\"] = x[\"rms\"].unsqueeze(dim=1).float()\n",
    "\n",
    "        out_mfcc = self.mfcc_net(x[\"mfcc\"])\n",
    "        out_mel = self.mel_net(x[\"mel\"])\n",
    "\n",
    "        out_zcr = self.zcr_net(x[\"zcr\"])\n",
    "        out_rms = self.rms_net(x[\"rms\"])\n",
    "\n",
    "        combined = torch.cat([out_mfcc, out_zcr, out_rms, out_mel], dim=1)\n",
    "\n",
    "        return combined\n",
    "\n",
    "\n",
    "    def init_hidden(self, batch):\n",
    "        hidden = torch.zeros(self.rnn_num_layers*2, batch, self.rnn_hidden_size).float().to(device)\n",
    "        cell = torch.zeros(self.rnn_num_layers*2, batch, self.rnn_hidden_size).float().to(device)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20e15f4",
   "metadata": {
    "id": "Sfcc-gTdbl6d",
    "papermill": {
     "duration": 0.047282,
     "end_time": "2024-09-19T03:40:11.501355",
     "exception": false,
     "start_time": "2024-09-19T03:40:11.454073",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<br>\n",
    "<hr>\n",
    "<br>\n",
    "\n",
    "## The Multimodal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b9b6be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:11.595151Z",
     "iopub.status.busy": "2024-09-19T03:40:11.594718Z",
     "iopub.status.idle": "2024-09-19T03:40:11.613068Z",
     "shell.execute_reply": "2024-09-19T03:40:11.611774Z"
    },
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1689170802028,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "nV5HuO1ZkMLr",
    "papermill": {
     "duration": 0.068538,
     "end_time": "2024-09-19T03:40:11.615872",
     "exception": false,
     "start_time": "2024-09-19T03:40:11.547334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MainMultimodal(nn.Module):\n",
    "    def __init__(self, num_classes, trainable=False, fine_tune_limit=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "#         # define video extractor, cut off FCN layer\n",
    "        self.video_extractor = R2plus1D\n",
    "\n",
    "#         # cut off layer fcn\n",
    "        self.video_extractor.fc = PassThrough()\n",
    "\n",
    "\n",
    "        # define audio extractor\n",
    "        self.audio_extractor = AudioFeatureExtractor(rnn_hidden_size=32, rnn_num_layers=1).to(device)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.LayerNorm(512 + 5632),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512 + 5632, num_classes, bias=True),\n",
    "        )\n",
    "\n",
    "        # init dual gpu usuage\n",
    "        self.video_extractor = nn.DataParallel(self.video_extractor)\n",
    "        self.audio_extractor = nn.DataParallel(self.audio_extractor)\n",
    "\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "            Set the model to trainable false\n",
    "        \"\"\"\n",
    "        if trainable is False:\n",
    "            for param in self.video_extractor.parameters():\n",
    "                param.requires_grad = False\n",
    "        else:\n",
    "\n",
    "            \"\"\"\n",
    "                Train all layers\n",
    "            \"\"\"\n",
    "            if fine_tune_limit == 'all':\n",
    "                for param in self.video_extractor.parameters():\n",
    "                    param.requires_grad = True\n",
    "\n",
    "            else:\n",
    "                \"\"\"\n",
    "                    Set the fine tune limits\n",
    "                \"\"\"\n",
    "                count = 0 # keep track for layer count\n",
    "                length = sum(1 for _ in self.video_extractor.module.children()) # get the length of layers\n",
    "                limit = length - fine_tune_limit # set the limit [if length is 7, then limit = 7-2(default) = 5 ---> if count is = or above this we set to trainable ]\n",
    "\n",
    "\n",
    "                for child in self.video_extractor.module.children():\n",
    "                    if count >= limit:\n",
    "                        for param in child.parameters():\n",
    "                            param.requires_grad = True\n",
    "                    else:\n",
    "                        for param in child.parameters():\n",
    "                            param.requires_grad = False\n",
    "\n",
    "                    count += 1\n",
    "\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, video, audio):\n",
    "\n",
    "        video = torch.permute(video, (0,2,1,3,4))\n",
    "\n",
    "\n",
    "        video_feature_values = self.video_extractor(video)\n",
    "\n",
    "        audio_feature_values = self.audio_extractor(audio)\n",
    "\n",
    "\n",
    "        del video, audio\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "        combined = torch.cat([video_feature_values, audio_feature_values], dim=1)\n",
    "\n",
    "        out_logits = self.fc(combined)\n",
    "        out_softmax = self.softmax(out_logits)\n",
    "\n",
    "\n",
    "        return out_logits, out_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7442e60c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:11.708813Z",
     "iopub.status.busy": "2024-09-19T03:40:11.707220Z",
     "iopub.status.idle": "2024-09-19T03:40:11.747733Z",
     "shell.execute_reply": "2024-09-19T03:40:11.745675Z"
    },
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1689170802029,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "2cwFz_w-JrG4",
    "papermill": {
     "duration": 0.091168,
     "end_time": "2024-09-19T03:40:11.751604",
     "exception": false,
     "start_time": "2024-09-19T03:40:11.660436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "modelV1 = MainMultimodal(len(idx2class), trainable=True, fine_tune_limit=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94318af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:11.847512Z",
     "iopub.status.busy": "2024-09-19T03:40:11.847025Z",
     "iopub.status.idle": "2024-09-19T03:40:11.853283Z",
     "shell.execute_reply": "2024-09-19T03:40:11.851823Z"
    },
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1689170802030,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "njefzEopbl6g",
    "papermill": {
     "duration": 0.058734,
     "end_time": "2024-09-19T03:40:11.856635",
     "exception": false,
     "start_time": "2024-09-19T03:40:11.797901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# next(modelV1.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a7fb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:11.949314Z",
     "iopub.status.busy": "2024-09-19T03:40:11.948779Z",
     "iopub.status.idle": "2024-09-19T03:40:11.959071Z",
     "shell.execute_reply": "2024-09-19T03:40:11.957521Z"
    },
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1689170802031,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "Hh67CLS0KP4p",
    "papermill": {
     "duration": 0.059274,
     "end_time": "2024-09-19T03:40:11.962038",
     "exception": false,
     "start_time": "2024-09-19T03:40:11.902764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(params=modelV1.parameters(), lr=hyperparams[\"lr\"], betas=hyperparams[\"adam_betas\"], weight_decay=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode='min', factor=0.1, patience=10, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991eb382",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:12.056591Z",
     "iopub.status.busy": "2024-09-19T03:40:12.056118Z",
     "iopub.status.idle": "2024-09-19T03:40:12.085567Z",
     "shell.execute_reply": "2024-09-19T03:40:12.083987Z"
    },
    "executionInfo": {
     "elapsed": 69,
     "status": "ok",
     "timestamp": 1689170802032,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "YZaA9yP7J6DE",
    "papermill": {
     "duration": 0.079878,
     "end_time": "2024-09-19T03:40:12.088860",
     "exception": false,
     "start_time": "2024-09-19T03:40:12.008982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, dataloader, optimizer, loss_fn, accuracy_fn=None, save_memory=False):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    try:\n",
    "        wandb.watch(model, criterion=loss_fn, log=\"all\", log_freq=10)\n",
    "    except:\n",
    "        print(\"NOT LOGGING TO WANDB\")\n",
    "        \n",
    "    for batch, (videos, audios, labels, video_paths, audio_paths) in enumerate(dataloader):\n",
    "        labels = labels.type(torch.LongTensor)\n",
    "        videos, labels = videos.to(device), labels.to(device)\n",
    "\n",
    "        y_logits, y_softmax = model(videos, audios)\n",
    "        y_logits, y_softmax = y_logits.to(device), y_softmax.to(device)\n",
    "\n",
    "        # print(y_logits.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        preds = y_softmax.argmax(dim=1).to(device)\n",
    "        videos = videos.detach().cpu()\n",
    "        # audios = audios.detach().cpu()\n",
    "        del videos, audios\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "        # print(labels.shape, preds.shape)\n",
    "\n",
    "        loss = loss_fn(y_logits, labels)\n",
    "        acc = accuracy_fn(preds, labels, num_classes=len(idx2class))\n",
    "        train_loss += loss.item()\n",
    "        train_acc += acc\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        if batch == 0 or batch % 1000 == 0 or batch == len(dataloader) - 1:\n",
    "            sample = random.randint(1, y_logits.shape[0])-1\n",
    "            print(f\"Batch: #{batch} | Train Loss: {loss} | Train Accuracy: {acc}\")\n",
    "            show_example(video_paths[sample], audio_paths[sample], preds[sample].detach().cpu().item(), labels[sample].detach().cpu().item(), save_memory)\n",
    "\n",
    "        del labels\n",
    "        del video_paths\n",
    "        del audio_paths\n",
    "        preds = preds.detach().cpu()\n",
    "        del preds\n",
    "        y_logits = y_logits.detach().cpu()\n",
    "        del y_logits\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "    print(f\"Total Train loss: {train_loss} | Total Train accuracy: {train_acc}\")\n",
    "    return train_loss, train_acc\n",
    "\n",
    "\n",
    "def eval_step(model: torch.nn.Module, dataloader, loss_fn, accuracy_fn=None, save_memory=False, confusion_matrix=False):\n",
    "    eval_loss = 0.0\n",
    "    eval_acc = 0.0\n",
    "\n",
    "    y_true = []\n",
    "    y_preds = []\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (videos, audios, labels, video_paths, audio_paths) in enumerate(dataloader):\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            videos, labels = videos.to(device), labels.to(device)\n",
    "\n",
    "            y_logits, y_softmax = model(videos, audios)\n",
    "            y_logits, y_softmax = y_logits.to(device), y_softmax.to(device)\n",
    "\n",
    "            preds = y_softmax.argmax(dim=1).to(device)\n",
    "\n",
    "            if confusion_matrix:\n",
    "                y_preds.extend(preds.detach().cpu().numpy())\n",
    "                y_true.extend(labels.detach().cpu().numpy())\n",
    "\n",
    "            videos = videos.detach().cpu()\n",
    "            # audios = audios.detach().cpu()\n",
    "            del videos, audios\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "\n",
    "            loss = loss_fn(y_logits, labels)\n",
    "            acc = accuracy_fn(preds, labels, num_classes=len(idx2class))\n",
    "            eval_loss += loss.item()\n",
    "            eval_acc += acc\n",
    "\n",
    "\n",
    "            if batch == 0 or batch % 1000 == 0 or batch == len(dataloader) - 1:\n",
    "                sample = random.randint(1, y_logits.shape[0])-1\n",
    "                print(f\"Batch: #{batch} | Eval. Loss: {loss} | Eval. Accuracy: {acc}\")\n",
    "                show_example(video_paths[sample], audio_paths[sample], preds[sample].detach().cpu().item(), labels[sample].detach().cpu().item(), save_memory)\n",
    "\n",
    "            del labels\n",
    "            del video_paths\n",
    "            del audio_paths\n",
    "            preds = preds.detach().cpu()\n",
    "            del preds\n",
    "            y_logits = y_logits.detach().cpu()\n",
    "            del y_logits\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "\n",
    "        eval_loss /= len(dataloader)\n",
    "        eval_acc /= len(dataloader)\n",
    "\n",
    "    print(f\"Total Eval. Loss: {eval_loss} | Total Eval. Accuracy: {eval_acc}\")\n",
    "\n",
    "    if confusion_matrix:\n",
    "        return eval_loss, eval_acc, y_true, y_preds\n",
    "    else:\n",
    "        return eval_loss, eval_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d30e6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:12.178335Z",
     "iopub.status.busy": "2024-09-19T03:40:12.177749Z",
     "iopub.status.idle": "2024-09-19T03:40:12.189219Z",
     "shell.execute_reply": "2024-09-19T03:40:12.187866Z"
    },
    "executionInfo": {
     "elapsed": 68,
     "status": "ok",
     "timestamp": 1689170802032,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "DFW2EX8Nbl6j",
    "outputId": "f12b918a-5f2d-4142-ed18-1bce449cf3a5",
    "papermill": {
     "duration": 0.060301,
     "end_time": "2024-09-19T03:40:12.192069",
     "exception": false,
     "start_time": "2024-09-19T03:40:12.131768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a5d170",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:12.283650Z",
     "iopub.status.busy": "2024-09-19T03:40:12.283181Z",
     "iopub.status.idle": "2024-09-19T03:40:12.290091Z",
     "shell.execute_reply": "2024-09-19T03:40:12.288452Z"
    },
    "executionInfo": {
     "elapsed": 46,
     "status": "ok",
     "timestamp": 1689170802033,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "gWfBz3SBbl6j",
    "papermill": {
     "duration": 0.057178,
     "end_time": "2024-09-19T03:40:12.293150",
     "exception": false,
     "start_time": "2024-09-19T03:40:12.235972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = []\n",
    "train_loss_history = []\n",
    "eval_loss_history = []\n",
    "\n",
    "train_accuracy_history = []\n",
    "eval_accuracy_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0286c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:12.386322Z",
     "iopub.status.busy": "2024-09-19T03:40:12.385850Z",
     "iopub.status.idle": "2024-09-19T03:40:12.392414Z",
     "shell.execute_reply": "2024-09-19T03:40:12.390730Z"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "ok",
     "timestamp": 1689170802034,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "SCb7QSi5bl6k",
    "papermill": {
     "duration": 0.058454,
     "end_time": "2024-09-19T03:40:12.395757",
     "exception": false,
     "start_time": "2024-09-19T03:40:12.337303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b8e662",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:12.485105Z",
     "iopub.status.busy": "2024-09-19T03:40:12.483592Z",
     "iopub.status.idle": "2024-09-19T03:40:12.495743Z",
     "shell.execute_reply": "2024-09-19T03:40:12.494316Z"
    },
    "papermill": {
     "duration": 0.060145,
     "end_time": "2024-09-19T03:40:12.499032",
     "exception": false,
     "start_time": "2024-09-19T03:40:12.438887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, filename=\"checkpoint.pth.tar\"):\n",
    "    torch.save(state, filename)\n",
    "    \n",
    "def load_checkpoint(model, optimizer, filename=\"checkpoint.pth.tar\"):\n",
    "    checkpoint = torch.load(filename)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_eval_loss = checkpoint['best_eval_loss']\n",
    "    \n",
    "    return model, optimizer, start_epoch, best_eval_loss\n",
    "\n",
    "def load_checkpoint_wandb(model, optimizer, filename, run_path):\n",
    "    with wandb.restore(filename, run_path=run_path) as io:\n",
    "        name = io.name\n",
    "    checkpoint = torch.load(name, map_location=torch.device(device))\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_eval_loss = checkpoint['best_eval_loss']\n",
    "    \n",
    "    return model, optimizer, start_epoch, best_eval_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c424ee9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:12.590794Z",
     "iopub.status.busy": "2024-09-19T03:40:12.590271Z",
     "iopub.status.idle": "2024-09-19T03:40:12.596980Z",
     "shell.execute_reply": "2024-09-19T03:40:12.595263Z"
    },
    "papermill": {
     "duration": 0.055538,
     "end_time": "2024-09-19T03:40:12.600054",
     "exception": false,
     "start_time": "2024-09-19T03:40:12.544516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d9b3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:12.688266Z",
     "iopub.status.busy": "2024-09-19T03:40:12.687734Z",
     "iopub.status.idle": "2024-09-19T03:40:12.694647Z",
     "shell.execute_reply": "2024-09-19T03:40:12.693119Z"
    },
    "papermill": {
     "duration": 0.05438,
     "end_time": "2024-09-19T03:40:12.697707",
     "exception": false,
     "start_time": "2024-09-19T03:40:12.643327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_eval_loss = 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4603fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:16.125612Z",
     "iopub.status.busy": "2024-09-19T03:40:16.125145Z",
     "iopub.status.idle": "2024-09-19T03:40:16.131950Z",
     "shell.execute_reply": "2024-09-19T03:40:16.130446Z"
    },
    "papermill": {
     "duration": 0.057466,
     "end_time": "2024-09-19T03:40:16.135231",
     "exception": false,
     "start_time": "2024-09-19T03:40:16.077765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(start_epoch, best_eval_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51149cb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:16.226810Z",
     "iopub.status.busy": "2024-09-19T03:40:16.224925Z",
     "iopub.status.idle": "2024-09-19T03:40:16.234438Z",
     "shell.execute_reply": "2024-09-19T03:40:16.233122Z"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "aborted",
     "timestamp": 1689170802035,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "x36S97zpL1Ak",
    "papermill": {
     "duration": 0.058323,
     "end_time": "2024-09-19T03:40:16.237465",
     "exception": false,
     "start_time": "2024-09-19T03:40:16.179142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "save_memory = True\n",
    "\n",
    "with wandb.init(project=\"multimodal-ser\", name='cremad-ablation-C'):\n",
    "    \n",
    "    wandb.define_metric(\"epoch\")\n",
    "    wandb.define_metric(\"train/*\", step_metric=\"epoch\")\n",
    "    wandb.define_metric(\"val/*\", step_metric=\"epoch\")\n",
    "    \n",
    "    if save_memory:\n",
    "        print(\"\\tSave memory mode is on. Set `save_memory=False` to see video-audio examples\")\n",
    "\n",
    "    start = time.time()\n",
    "    for epoch in range(start_epoch, hyperparams[\"epochs\"]):\n",
    "        print(f\"========================== Starting Epoch: # {epoch} ==========================\")\n",
    "\n",
    "        inference_start = time.time()\n",
    "\n",
    "        train_loss, train_acc = train_step(modelV1, trainloader, optim, loss_fn, multiclass_f1_score, save_memory=save_memory)\n",
    "        eval_loss, eval_acc = eval_step(modelV1, cvloader, loss_fn, multiclass_f1_score, save_memory=save_memory)\n",
    "        scheduler.step(eval_loss)\n",
    "        \n",
    "        wandb.log({\"train/loss\": train_loss, \"val/loss\": eval_loss, \"train/f1_acc\": train_acc, \"val/f1_acc\": eval_acc}, step=epoch)\n",
    "        \n",
    "        inference_total = time.time() - inference_start\n",
    "        convert_inf = str(datetime.timedelta(seconds=inference_total))\n",
    "\n",
    "\n",
    "        print(f\"Epoch: #{epoch} | Total Train Loss: {train_loss} | Total Eval. Loss: {eval_loss} | Train Acc: {train_acc * 100}% | Eval Acc: {eval_acc * 100}% in {convert_inf}\")\n",
    "\n",
    "\n",
    "        epochs.append(epoch+1)\n",
    "        train_loss_history.append(train_loss)\n",
    "        eval_loss_history.append(eval_loss)\n",
    "        train_accuracy_history.append(train_acc.detach().cpu()*100)\n",
    "        eval_accuracy_history.append(eval_acc.detach().cpu()*100)\n",
    "\n",
    "        if eval_loss < best_eval_loss:\n",
    "            best_eval_loss = eval_loss\n",
    "            # save best checkpoint\n",
    "            save_checkpoint({\n",
    "                'model_state_dict': modelV1.state_dict(),\n",
    "                'optimizer_state_dict': optim.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'best_eval_loss': best_eval_loss\n",
    "            }, filename=\"best_checkpoint.pth.tar\")\n",
    "            wandb.save('/kaggle/working/best_checkpoint.pth.tar')\n",
    "\n",
    "        # save global checkpoint\n",
    "        save_checkpoint({\n",
    "            'model_state_dict': modelV1.state_dict(),\n",
    "            'optimizer_state_dict': optim.state_dict(),\n",
    "            'epoch': epoch + 1,\n",
    "            'best_eval_loss': eval_loss\n",
    "        }, filename=\"checkpoint.pth.tar\")\n",
    "        wandb.save('/kaggle/working/checkpoint.pth.tar')\n",
    "\n",
    "        del train_loss, eval_loss, train_acc, eval_acc\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e14067",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:16.327516Z",
     "iopub.status.busy": "2024-09-19T03:40:16.326958Z",
     "iopub.status.idle": "2024-09-19T03:40:16.575742Z",
     "shell.execute_reply": "2024-09-19T03:40:16.574371Z"
    },
    "executionInfo": {
     "elapsed": 47,
     "status": "aborted",
     "timestamp": 1689170802041,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "YRIwKJd2bl6l",
    "papermill": {
     "duration": 0.296811,
     "end_time": "2024-09-19T03:40:16.578414",
     "exception": false,
     "start_time": "2024-09-19T03:40:16.281603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d327563",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:16.864732Z",
     "iopub.status.busy": "2024-09-19T03:40:16.863263Z",
     "iopub.status.idle": "2024-09-19T03:40:16.870809Z",
     "shell.execute_reply": "2024-09-19T03:40:16.869454Z"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "aborted",
     "timestamp": 1689170802044,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "5Prr5Tsibl6m",
    "papermill": {
     "duration": 0.05506,
     "end_time": "2024-09-19T03:40:16.873599",
     "exception": false,
     "start_time": "2024-09-19T03:40:16.818539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# epoch = hyperparams[\"epochs\"]\n",
    "epoch = len(epochs) + 1\n",
    "\n",
    "plt.plot(epochs, train_loss_history, color='dodgerblue', label='Train Loss')\n",
    "plt.plot(epochs, eval_loss_history, color='orange', label='Eval. Loss')\n",
    "\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss Value\")\n",
    "plt.title(f\"Train and Eval. Loss along {epoch} epochs (RAVDESS)\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"Loss curves.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7371f73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:16.962185Z",
     "iopub.status.busy": "2024-09-19T03:40:16.960265Z",
     "iopub.status.idle": "2024-09-19T03:40:16.967661Z",
     "shell.execute_reply": "2024-09-19T03:40:16.966066Z"
    },
    "executionInfo": {
     "elapsed": 49,
     "status": "aborted",
     "timestamp": 1689170802045,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "sLHCcmpBbl6n",
    "papermill": {
     "duration": 0.054305,
     "end_time": "2024-09-19T03:40:16.970525",
     "exception": false,
     "start_time": "2024-09-19T03:40:16.916220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(epochs, train_accuracy_history, color='dodgerblue', label='Train Accuracy')\n",
    "plt.plot(epochs, eval_accuracy_history, color='orange', label='Eval. Accuracy')\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"F1 Score Value\")\n",
    "plt.title(f\"Train and Eval. Accuracy along {epoch} epochs (RAVDESS)\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.savefig(\"F1-Score curves.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c0a7a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T03:40:17.255987Z",
     "iopub.status.busy": "2024-09-19T03:40:17.254310Z",
     "iopub.status.idle": "2024-09-19T07:50:26.926961Z",
     "shell.execute_reply": "2024-09-19T07:50:26.924959Z"
    },
    "executionInfo": {
     "elapsed": 1754232,
     "status": "ok",
     "timestamp": 1689172780789,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "CcqkbFj4bl6p",
    "outputId": "52b18465-de10-40fa-89c0-bf169d4d0486",
    "papermill": {
     "duration": 15009.725399,
     "end_time": "2024-09-19T07:50:26.931930",
     "exception": false,
     "start_time": "2024-09-19T03:40:17.206531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "modelV1, _, _, _ = load_checkpoint(modelV1, optim, \"./best_checkpoint.pth.tar\")\n",
    "\n",
    "test_loss, test_acc, y_true, y_preds = eval_step(modelV1, testloader, loss_fn, multiclass_f1_score, save_memory=False, confusion_matrix=True)\n",
    "test_acc = test_acc.detach().cpu()\n",
    "\n",
    "print(f\"Test loss: {test_loss}\\tTest Accuracy: {test_acc*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33fbd13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T07:50:27.067741Z",
     "iopub.status.busy": "2024-09-19T07:50:27.066945Z",
     "iopub.status.idle": "2024-09-19T07:50:27.076657Z",
     "shell.execute_reply": "2024-09-19T07:50:27.075432Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1689173398030,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "EHaY50qZlC0t",
    "papermill": {
     "duration": 0.081743,
     "end_time": "2024-09-19T07:50:27.080387",
     "exception": false,
     "start_time": "2024-09-19T07:50:26.998644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_margins(ax, x=0.05, y=0.05):\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    xmargin = (xlim[1]-xlim[0])*x\n",
    "    ymargin = (ylim[1]-ylim[0])*y\n",
    "\n",
    "    ax.set_xlim(xlim[0]-xmargin,xlim[1]+xmargin)\n",
    "    ax.set_ylim(ylim[0]-ymargin,ylim[1]+ymargin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7db132",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T07:50:27.204201Z",
     "iopub.status.busy": "2024-09-19T07:50:27.203756Z",
     "iopub.status.idle": "2024-09-19T07:50:37.692416Z",
     "shell.execute_reply": "2024-09-19T07:50:37.690611Z"
    },
    "executionInfo": {
     "elapsed": 1179,
     "status": "ok",
     "timestamp": 1689173911796,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "M7Gd_x1VuESp",
    "outputId": "535c8233-f086-40a5-c13c-780c548fcab0",
    "papermill": {
     "duration": 10.555701,
     "end_time": "2024-09-19T07:50:37.696942",
     "exception": false,
     "start_time": "2024-09-19T07:50:27.141241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = [v for k,v in idx2class.items()]\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true, y_preds)\n",
    "\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], index = [i for i in classes], columns = [i for i in classes])\n",
    "\n",
    "plt.figure(figsize = (12,7))\n",
    "\n",
    "s = sn.heatmap(df_cm, annot=True, cmap='Blues', fmt=\".2f\")\n",
    "\n",
    "plt.xlabel('Predicted Label', fontsize=14, labelpad=20, fontweight='bold')\n",
    "\n",
    "plt.ylabel('True Label', fontsize=14, labelpad=20, fontweight='bold')\n",
    "\n",
    "# format_margins(s, x=0.1)\n",
    "\n",
    "plt.savefig('confusion_matrix_crema.png', dpi=1200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baec211",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T07:50:38.078240Z",
     "iopub.status.busy": "2024-09-19T07:50:38.077700Z",
     "iopub.status.idle": "2024-09-19T07:50:38.148032Z",
     "shell.execute_reply": "2024-09-19T07:50:38.146407Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1689173822083,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "d5MVORi3bv99",
    "outputId": "390fc13f-3fe3-42e6-9e31-e61fd6f51fe9",
    "papermill": {
     "duration": 0.387833,
     "end_time": "2024-09-19T07:50:38.151323",
     "exception": false,
     "start_time": "2024-09-19T07:50:37.763490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_preds, target_names=[v for k,v in idx2class.items()], output_dict=True)\n",
    "\n",
    "df = pd.DataFrame(report).transpose()\n",
    "\n",
    "\n",
    "df = df.round(decimals=4)\n",
    "\n",
    "df.to_csv('classification_report_crema.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aa649f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-19T07:50:38.280477Z",
     "iopub.status.busy": "2024-09-19T07:50:38.279631Z",
     "iopub.status.idle": "2024-09-19T07:50:38.291664Z",
     "shell.execute_reply": "2024-09-19T07:50:38.289730Z"
    },
    "executionInfo": {
     "elapsed": 1747046,
     "status": "aborted",
     "timestamp": 1689172772712,
     "user": {
      "displayName": "Jawwadul Islam Fida",
      "userId": "01702761963171213851"
     },
     "user_tz": -360
    },
    "id": "6GLhygd0c2sQ",
    "papermill": {
     "duration": 0.082393,
     "end_time": "2024-09-19T07:50:38.295508",
     "exception": false,
     "start_time": "2024-09-19T07:50:38.213115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save stats\n",
    "with open(\"recorded.txt\", \"w\") as f:\n",
    "    f.write(\"R2plus1D & CNN+SE net attempt CREMA\\n\")\n",
    "    for i, line in enumerate(epochs):\n",
    "        f.write(f\"Epoch: {line}: | Train Loss: {train_loss_history[i]} | Train Accuracy: {train_accuracy_history[i]} | Eval Loss: {eval_loss_history[i]} | Eval Accuracy: {eval_accuracy_history[i]}\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "    f.write(\"\\n==================================================\\n\")\n",
    "    f.write(f\"On best weights => Test loss: {test_loss}\\tTest Accuracy: {test_acc*100}\")\n",
    "    f.write(\"\\n==================================================\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a35cc5",
   "metadata": {
    "id": "379Pvomcfxas",
    "papermill": {
     "duration": 0.061252,
     "end_time": "2024-09-19T07:50:38.418623",
     "exception": false,
     "start_time": "2024-09-19T07:50:38.357371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **Citations**\n",
    "\n",
    "1. Livingstone SR, Russo FA (2018) The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English. PLoS ONE 13(5): e0196391. https://doi.org/10.1371/journal.pone.0196391"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3517045,
     "sourceId": 6133877,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30559,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15130.744939,
   "end_time": "2024-09-19T07:50:41.478915",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-19T03:38:30.733976",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
